id: 777267
speaker: Tim Roughgarden 
speakerAffiliation: Stanford University
speakerUrl: http://theory.stanford.edu/~tim/
startDateTime: 2013-05-03 11:00:00
endDateTime: 2013-05-03 12:00:00
abstract: Theoretical computer science has brought new ideas and techniques to game and economic theory. A primary signature of the computer science approach is {em approximation} --- the idea of building credibility for a proposed solution by proving that its performance is always within a small factor of an ideal (and typically unimplementable) solution. We explain two of our recent contributions in this area, one motivated by networks and one by auctions.  We first discuss the "price of anarchy": how well does decentralized (or "selfish") behavior approximates centralized optimization? This concept has been analyzed in many applications, including network routing, resource allocation, network formation, health care, and even models of basketball. We highlight a new theory of robust price of anarchy bounds, which apply even to systems that are not in equilibrium.  Second, we consider auction design: for example, what selling procedure should be used to maximize the revenue of a seller? On the analysis side, we highlight a new framework that explicitly connects average-case (i.e., Bayesian) analysis, the dominant paradigm in economics, with the worst-case analysis approach common in computer science. On the design side, we provide a distribution-independent auction that performs, for a wide class of input distributions, almost as well as the distribution-specific optimal auction.
bio: Tim Roughgarden received his Ph.D. from Cornell University in 2002 and joined the Stanford CS department in 2004, where he is currently an associate professor. His research interests are in theoretical computer science, especially its interfaces with game theory and networks. He wrote the book "Selfish Routing and the Price of Anarchy" (MIT Press, 2005) and co-edited the book "Algorithmic Game Theory", with Nisan, Tardos, and Vazirani (Cambridge, 2007). His significant awards include the 2002 ACM Doctoral Dissertation Award (Honorable Mention), the 2003 Tucker Prize, a 2007 PECASE Award, the 2008 Shapley Lectureship of the Game Theory Society, the 2009 ACM Grace Murray Hopper Award, and the 2012 EATCS-ACM-SIGACT Godel Prize.
locationRoomNumber: 1122
eventWebsite: https://talks.cs.umd.edu/talks/267
title:  Porting the Computer Science Toolbox to Game Theory and Economics
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777344
speaker: Dr. Maneesh Agrawala
speakerAffiliation: University of California, Berkeley
speakerUrl: 
startDateTime: 2013-05-03 14:00:00
endDateTime: 2013-05-03 15:00:00
abstract: 
Storytelling is essential for communicating ideas. When they are well told, stories help us make sense of information, appreciate cultural or societal differences, and imagine living in entirely different worlds. Audio/visual stories in the form of radio programs, books-on-tape, podcasts, television, movies and animations, are especially powerful because they provide a richtisensory experience. Technological advances have made it easy to capturies using the microphones and cameras that are readily available in our mobile devices, but, the raw media rarelelling The best storytellers carefully compose, filter, edit and highlight the raw media to produce an engaging piece. Yet, the software tools they use to create and manipulate the raw audio/video media (e.g. Pro Tools, Photoshop, Premiere, Final Cut Pro, Maya etc.) force storytellers to work at a tediously low-level  selecting, filtering and layering pixels or cutting and transitioning between audio/video frames. While these tools provide flexible and precise control over the look and sound of the final result, they are notoriously difficult to learn and accessible primarily to experts. In this talk I'll present a number of recent projects that aim to significantly reduce the effort required to edit and produce high-quality audio/visual stories
bio: 
Maneesh Agrawala is an Associate Professor in Electrical Engineering and Computer Science at the University of California, Berkeley where he works on problems in visualization, computer graphics and human computer interaction. 

His focus is on investigating how cognitive design principles can be used to improve the effectiveness of visual displays. He received the SIGGRAPH Significant New Researcher award in 2008 and a MacArthur Foundation Fellowship in 2009.
locationRoomNumber: Room 2117
eventWebsite: https://talks.cs.umd.edu/talks/344
title: Storytelling Tools
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777329
speaker: Di-Wei Huang
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-03 14:30:00
endDateTime: 2013-05-03 16:00:00
abstract: 

Self-Organizing Maps (SOMs), inspired by maps of the external world that are formed in cortical regions of the brain, have been extensively used in visualizing high dimensional data. They exhibit the ability to discover, through unsupervised learning, non-linear projections to low dimensional (mostly 2-D) spaces that well preserve the relative relations of the original data. In the past, SOMs have generally been used to process static data, until more recently when they have been modified to handle temporal sequences. However, their computational applications are still limited by the fact that they mostly operate in isolation rather than being organized into architectures with multiple SOMs that can take advantage of their combined computing power. Therefore, I propose to build a multi-SOM system for processing multiple correlated temporal sequences. To achieve this goal, it is essential that the internal representations for each SOM be enriched beyond local and static representations, currently the mainstream encoding scheme for SOMs, so as to increase the amount and the robustness of information conveyed between SOMs, and to reduce timing requirement for reading neural activities of SOMs. In preliminary work, a type of spatiotemporal representation based on limit cycle attractors, rather than the usual static activity patterns, is studied with one-shot, multi-winner, and locally recurrent SOMs. This encoding scheme aims to both increase the expressiveness of SOMs' activity states and to reduce the precise timing requirements for accessing representations. The results identify conditions necessary to obtain limit cycles, and show that limit cycles are promising in terms of robustness and ability to serve as internal representations of temporal data. Accordingly, the proposed research plan includes investigating the effects of different architectural constructs for SOMs using limit cycle representations, building a multi-SOM system for processing multiple temporal sequences, and developing an adaptive control mechanism for the resultant system.
Examining Committee: 
Dr. James Reggia -  Chair 
Dr. Rance Cleaveland -  Deps Representative
Dr. Donald Perlis -  Committee Member
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/329
title: PhD Proposal: Multi-Self Organizing Map Architectures for Temporal Sequence Processing Based on Limit Cycle Attractors
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777335
speaker: Ashwin Kumar Kayyoor
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-06 10:00:00
endDateTime: 2013-05-06 11:30:00
abstract: 

The rapid increase in the data volumes encountered in many application domains has led to widespread adoption of parallel and distributed data management systems like parallel databases and MapReduce-based frameworks (e.g., Hadoop) in recent years. Use of such parallel or distributed frameworks is expected to accelerate in the coming years, putting further strain on already-scarce resources like compute power, network bandwidth, and energy. For reducing total execution times, there is a trend towards increasing the execution parallelism by spreading out data across a large number of machines. However, this often increases the total resource consumption, and especially energy consumption, significantly. In my dissertation research, I propose to develop data management techniques that minimize resource consumption through workload consolidation.
In the first part of my proposal, I focus on analytical workloads, consisting of read-only queries, being executed across a large number of machines. I argue that, for such workloads, minimizing the query latencies may not be critically important since the queries are often not run in an interactive mode. Instead, I propose that we should aim for reducing the total resource consumption by decreasing the degree of single-query execution parallelism, i.e., by trying to reduce the number of machines involved in the execution of a query (called query span). To that end, I propose workload-driven replica selection and placement algorithms that attempt to minimize the average query span by exploiting the fact that most distributed environments need to use replication for fault tolerance. Preliminary experiments show that judicious data placement and replication can dramatically reduce the average query spans resulting in significant reductions in the resource consumption.
In the second part of my proposal, I propose and study an in-memory MapReduce system optimized for performing complex analytics tasks on input data sizes that fit in a single machine's memory. I argue that systems like Hadoop that are designed to operate across a large number of machines are not optimal in performance for small and medium sized complex analytics tasks because of high startup costs, heavy disk activity, and wasteful checkpointing. I propose developing a prototype runtime called Hone that is both API and binary compatible with standard (distributed) Hadoop. In other words, we can take an existing Hadoop jar and run it, without modification, on a multi-core shared memory machine. This allows us to take existing Hadoop algorithms and find the most suitable runtime environment for execution on datasets of varying sizes.
Finally, I conclude the proposal with the future work I plan to pursue, which is divided into three parts: (a) supporting iterative algorithms in Hone, (b) supporting streaming analytics in Hone, and (c) workload-aware optimization of MapReduce workloads.
Examining Committee:
Dr. Amol Deshpande -  Chair
Dr. Alan Sussman -  Deps Representative
Dr. Jimmy Lin -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/335
title: PhD Proposal: Minimizing Resource Consumption through Consolidation in  Large-Scale Data Analysis Platforms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777337
speaker: Wenchao Zhou
speakerAffiliation: Department of Computer Science at Georgetown University
speakerUrl: http://www.cis.upenn.edu/~wenchaoz/
startDateTime: 2013-05-07 14:00:00
endDateTime: 2013-05-07 15:00:00
abstract: 

Operators of distributed systems often find themselves needing to answer forensic questions, in order to perform a variety of managerial tasks including fault detection, system debugging, accountability enforcement, and attack analysis.In thistalk, we will introduce Secure Network Provenance (SNP), an approach that provides the fundamental functionality required for answering such forensic questions -- the capability to "explain'' the existence (or change) of a certain distributed system state in a potentially adversarial environment.

We modelprovenance maintenance and querying as recursive queries over distributed relations, and propose security extensions toallow operators to reliably query provenanceinformation in adversarial environments. The extensions guarantee thatoperators can eventually detect the presence of compromised nodes thatlie or falsely implicate correct nodes.Finally, we discuss our work in the context of our longer term vision towardsprovably secure distributed systems.
bio: 

Wenchao Zhou is an Assistant Professor in the Department of Computer Science at Georgetown University.His research interests center on the use ofdata-centricandformal techniquestowards ensuringsafe and secure distributed systems. Dr. Zhou received the BSE degree in computer science from Tsinghua University in 2006, and the MSE and PhD degrees in computer science both from the University of Pennsylvania in 2009 and 2012 respectively.
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/337
title: Finding Needles in a Haystack: Secure Provenance in Distributed Systems
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777338
speaker: Nima Asadi
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-08 09:00:00
endDateTime: 2013-05-08 11:00:00
abstract: 

In recent years we have witnessed the growing popularity of social media among Internet users. The integration of social media in a variety of online services, together with the spread of smart phones, has changed the way we gossip, advertise, engage in political debates, and track public health. Social media and the online presence of news organizations have similarly revolutionized how news is created, distributed, and accessed. These changes, in turn, have brought about increasing engagement and contribution of users on the web, thereby making the web more dynamic.  A more dynamic web presents new challenges for web searchan important application of Information Retrieval (IR). A stream of new documents in various forms constantly flows into the web at a very high rate, adding to the old content. In many cases, documents quickly lose their relevance. In these time-sensitive environments, finding relevant content in response to user queries requires a real-time search service. This means that the search service must guarantee immediate availability of new content for search. In addition, the search service must offer a fastyet effectiveranking of documents, which requires an optimized search architecture. These aspects of todays web are at odds with how academic IR researchers have traditionally viewed the web, as a collection of static documents. Moreover, search architectures have received little attention in the IR literature. As a result, academic IR research, for the most part, does not provide a mechanism to efficiently handle a high-velocity stream of documents, nor does it facilitate real- time ranking.  In order to resolve these shortcomings, we need to adapt existing search architectures to the new characteristics of the web. To this end, this dissertation addresses the issues of real-time indexing and explores various search architectures for document ranking. We present an efficient mechanism to index a stream of documents in real-time, thereby enabling immediate availability of content for search. Our index structure works entirely in main memory and provides a mechanism to control inverted list contiguity, thereby enabling faster retrieval. Additionally, we consider document ranking with a machine-learned model, dubbed Learning to Rank (LTR), and introduce a novel multi-stage search architecture that enables fast retrieval and allows for more design flexibility. The stages of our architecture include candidate generation (top-k retrieval), feature extraction, and document re-ranking using tree-based LTR models. We compare this architecture with a traditional monolithic architecture where candidate generation and feature extraction occur simultaneously. As we lay out our multi-stage search architecture, we present optimizations to each stage to facilitate low-latency ranking. These optimizations include a fast approximate algorithm to retrieve top k documents that are potentially most relevant to an input query, document vector organizations for feature extraction, architecture-conscious implementations of tree ensembles for LTR using predication and vectorization, and algorithms to train tree-based LTR models that are fast to evaluate. We also study the efficiency-effectiveness tradeoffs of these techniques, and empirically evaluate our end-to-end architecture on microblog document collections.  As we argue in this work, the techniques from this dissertation can improve the efficiency of search for users without degrading search quality. As web becomes even more dynamic and information continues to be disseminated in real-time, adapting search services to conform to real-time settings will become ever more important. 
Examining Committee:
Committee Chair: Dr. Jimmy Lin
Dean's Representative: Dr. Carol Y. Espy-Wilson
Committee Members:  Dr. Hal Daume III
 Dr. Amol Deshpande
 Dr. Alan Sussman
bio: 
locationRoomNumber: 4185
eventWebsite: https://talks.cs.umd.edu/talks/338
title: PhD Defense: Multi-Stage Search Architectures for Streaming Documents
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777284
speaker: ALex Slivkins
speakerAffiliation: Microsoft Research Silicon Valley  Mountain View
speakerUrl: research.microsoft.com/en-us/people/slivkins/
startDateTime: 2013-05-10 13:00:00
endDateTime: 2013-05-10 14:00:00
abstract: 
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/284
title: to be announced
locationName: 
facilId: 19191919
buildingAbbreviation: 
buildingUrl: 
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777334
speaker: Christoph Koch
speakerAffiliation: EPFL
speakerUrl: http://people.epfl.ch/christoph.koch
startDateTime: 2013-05-13 11:00:00
endDateTime: 2013-05-13 12:00:00
abstract: 



In this talk, I present a system for the automatic synthesis of efficient algorithms specialized for a particular memory hierarchy and a set of storage devices. The developer provides two independent inputs: 1) an algorithm that ignores memory hierarchy and external storage aspects; and 2) a description of the target memory hierarchy, including its topology and parameters. Our system is able to automatically synthesize memory-hierarchy and storage-device-aware algorithms out of those specifications, for tasks such as joins and sorting. The framework is extensible and allows developers to quickly synthesize custom out-of-core algorithms as new storage technologies become available.
bio: 

Christoph Koch is a professor of Computer Science at EPFL, specializing in data management. Until 2010, he was an Associate Professor in the Department of Computer Science at Cornell University. Previously to this, from 2005 to 2007, he was an Associate Professor of Computer Science at Saarland University. Earlier, he obtained his PhD in Artificial Intelligence from TU Vienna and CERN (2001), was a postdoctoral researcher at TU Vienna and the University of Edinburgh (2001-2003), and an assistant professor at TU Vienna (2003-2005). He obtained his Habilitation degree in 2004.He has won Best Paper Awards at PODS 2002, ICALP 2005, and SIGMOD 2011, an Outrageous Ideas and Vision Paper Award at CIDR 2013, a Google Research Award (in 2009), and an ERC Grant (in 2011). He is a PI of the Billion-Euro EUFET Flagship Human Brain Project. He (co-)chaired the program committees of DBPL 2005, WebDB 2008, and ICDE 2011, and was PC vice-chair of ICDE 2008 and ICDE 2009. He has served on the editorial board of ACM Transactions on Internet Technology as well as in numerous program committees.He currently serves as PC co-chair of VLDB 2013 and Editor-in-Chief of PVLDB.
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/334
title: Automatic Synthesis of Out-of-Core Algorithms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777340
speaker: John Alexis Guerra Gomez
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-13 12:00:00
endDateTime: 2013-05-13 14:00:00
abstract: 

Hierarchies are a useful way of representing data. The parent-to-child relationships they define facilitate the analysis of a dataset by breaking it down into its component parts. Representing data as hierarchies can also be used to track changes to a dataset over time or between versions. For example, analysts can use hierarchies to uncover changes in the US Federal Budget in the last twenty years, by grouping accounts by Agencies and Bureaus. Similarly, a company manager can analyze changes to their product sales due to the holiday season by breaking them up by markets and product categories. Exploring differences in such trees could help them understand changes in the data. However, comparing hierarchies is a difficult task, even when comparing two trees with a small number of nodes. To address this, I used information visualization techniques to support data comparison tasks using hierarchies. After evaluating my techniques with domain experts on real world problems, I identified and addressed two main research topics:  First, I tackled the problem of comparing two versions of a tree by using two types of change, while most of the significant work on this topic has focused only on changes in node values or changes in topology. TreeVersity (http://hcil.cs.umd.edu/treeversity) is a comparison tool that allows users to explore changes between two versions of a tree by tracking node value differences, and newly created or removed nodes. Domain experts using TreeVersity were excited to discover differences in the trees, but expressed a desire to explore the evolution of a dataset over time. To that end, they suggested to apply TreeVersity comparison capabilities to non inherently hierarchical datasets.  Thus, I then addressed the problem of exploring changes over time in datasets that can be categorized as trees. TreeVersity2 (http://treeversity.cattlab.umd.edu is a web-based data comparison tool that allows users to explore a tree that change over time and of datasets that are not inherently hierarchical, by categorizing them by its attributes. TreeVersity2 also helps users navigate the sometimes large amounts of differences between versions of a tree using an interactive textual reporting tool.  My research has resulted in two main contributions: First, the introduction of the Bullet, a visualization glyph to represent four characteristics of change (as described in Section [sec:Contributions]) in tree nodes, and the implementation of the Bullet in TreeVersity. Second, the creation of the StemView, a tree visualization technique that represents five characteristics of change in all the nodes of a tree (not just the leaves), and the implementation of the StemView in TreeVersity2. Furthermore, my research resulted in the development of the reporting tool, another feature of TreeVersity2, which helps users navigate outstanding changes in the tree with textual representations and coordinated interactions. Moreover, these developments have been tested in 13 case studies with domain experts on real world comparison problems. The case studies have validated the utility and flexibility of my approaches. Finally, my research opens possibilities for future research on comparing hierarchical structures. 
Examining Committee:
Committee Chair: Dr. Ben Shneiderman
Dean's Representative: Dr. David Lovell
Committee Members:  Dr. Catherine Plaisant
 Dr. Lise Getoor
 Dr. Ben Bederson
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/340
title: PhD Defense: Exploring Differences in Multivariate Datasets Using Hierarchies:  An Interactive Information Visualization Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777341
speaker: Jochen Koenemann
speakerAffiliation: Associate Professor, University of Waterloo 
speakerUrl: http://www.math.uwaterloo.ca/~jochen/
startDateTime: 2013-05-13 13:00:00
endDateTime: 2013-05-13 14:00:00
abstract: The first part of this talk focuses on a network diffusion model that was recently introduced by Goldberg  Liu (SODA'13). Goldberg  Liu's model adapts the earlier linear threshold model of Kempe, Kleinberg  Tardos (KDD'03) in an effort to capture aspects of technology adaptation processes in networks. We present new, improved, yet simple algorithms for the so called Influence Maximization problem in this setting.
A key component of our algorithm is a Langrangean multiplier preserving (LMP) algorithm for the Prize-collecting Node-weighted Steiner Tree problem (PC-NWST). This problem had been studied in prior work by Moss and Rabani (STOC'01  SICOMP'07) who presented a primal-dual O(log |V|) approximate and LMP algorithm, and showed that this is best possible unless NP=P.
We demonstrate that Moss  Rabani's algorithm for PC-NWST is seriously flawed. We then present a new, fundamentally different primal-dual method achieving the same performance guarantee. Our algorithm introduces several novel features to the primal-dual method that may be of independent interest.
Joint work with Laura Sanita and Sina Sadeghian
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/341
title: Network Diffusion & Node-Weighted Steiner Trees
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777345
speaker: Vahid Liaghat
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-14 09:30:00
endDateTime: 2013-05-14 11:00:00
abstract: 

An offline algorithm is one that knows the entire input in advance. An online algorithm, however, processes its input in a serial fashion. In contrast to offline algorithms, an online algorithm works in a local fashion and has to make irrevocable decisions without having the entire input. Online algorithms are often not optimal since their irrevocable decisions may turn out to be inefficient after receiving the rest of the input. For a given online problem, the goal is to design algorithms which are competitive against the offline optimal solutions.  We study the competitive analysis of fundamental problems in the literature such as online matching, online Steiner connectivity, and the k-server problem. Although there are many generic tools for solving an optimization problem in the offline paradigm, much less is known for tackling online problems. A representative example is bipartite matching. Even though bipartite matching is easily computable in the offline setting, solving the problem online is shown to be very challenging. The main focus of our work is to design generic techniques for solving linear optimization problems where the solution space is restricted via a set of linear constraints. A general family of these problems are online packing/covering problems. Our work so far shows that for several seemingly unrelated problems, primal-dual techniques can be successfully applied as a unifying approach for solving these problems. We believe this leads to generic algorithmic frameworks for solving online problems.  In this proposal, we first show the effectiveness of our techniques for both adversarial settings and stochastic settings. In particular, we introduce new techniques for solving two online linear optimization problems, namely, the stochastic generalized assignment problem and the network design problems characterized by proper functions. The former belongs to the family of online packing problems while the later belongs to the family of online covering problems. We next describe the challenges ahead for venturing deeper into either of these major families of problems.
Examining Committee:
Dr. Mohammad Taghi Hajiaghayi -  Chair
Dr. Hector Corrado Bravo -  Deps Representative
Dr. Aravind Srinivasan -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/345
title: PhD Proposal: Online Algorithms with the Uncertainty of Future, A Primal-Dual Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777342
speaker: Panos Chrysanthis
speakerAffiliation: University of Pittsburgh
speakerUrl: http://panos.cs.pitt.edu/
startDateTime: 2013-05-14 11:00:00
endDateTime: 2013-05-14 12:00:00
abstract: TBA
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/342
title: TBA
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777332
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-22 08:30:00
endDateTime: 2013-05-22 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/332
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777333
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-23 08:30:00
endDateTime: 2013-05-23 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/333
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-02 08:57:18
Info: Event is already in the database
id: 777267
speaker: Tim Roughgarden 
speakerAffiliation: Stanford University
speakerUrl: http://theory.stanford.edu/~tim/
startDateTime: 2013-05-03 11:00:00
endDateTime: 2013-05-03 12:00:00
abstract: Theoretical computer science has brought new ideas and techniques to game and economic theory. A primary signature of the computer science approach is {em approximation} --- the idea of building credibility for a proposed solution by proving that its performance is always within a small factor of an ideal (and typically unimplementable) solution. We explain two of our recent contributions in this area, one motivated by networks and one by auctions.  We first discuss the "price of anarchy": how well does decentralized (or "selfish") behavior approximates centralized optimization? This concept has been analyzed in many applications, including network routing, resource allocation, network formation, health care, and even models of basketball. We highlight a new theory of robust price of anarchy bounds, which apply even to systems that are not in equilibrium.  Second, we consider auction design: for example, what selling procedure should be used to maximize the revenue of a seller? On the analysis side, we highlight a new framework that explicitly connects average-case (i.e., Bayesian) analysis, the dominant paradigm in economics, with the worst-case analysis approach common in computer science. On the design side, we provide a distribution-independent auction that performs, for a wide class of input distributions, almost as well as the distribution-specific optimal auction.
bio: Tim Roughgarden received his Ph.D. from Cornell University in 2002 and joined the Stanford CS department in 2004, where he is currently an associate professor. His research interests are in theoretical computer science, especially its interfaces with game theory and networks. He wrote the book "Selfish Routing and the Price of Anarchy" (MIT Press, 2005) and co-edited the book "Algorithmic Game Theory", with Nisan, Tardos, and Vazirani (Cambridge, 2007). His significant awards include the 2002 ACM Doctoral Dissertation Award (Honorable Mention), the 2003 Tucker Prize, a 2007 PECASE Award, the 2008 Shapley Lectureship of the Game Theory Society, the 2009 ACM Grace Murray Hopper Award, and the 2012 EATCS-ACM-SIGACT Godel Prize.
locationRoomNumber: 1122
eventWebsite: https://talks.cs.umd.edu/talks/267
title:  Porting the Computer Science Toolbox to Game Theory and Economics
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777344
speaker: Dr. Maneesh Agrawala
speakerAffiliation: University of California, Berkeley
speakerUrl: 
startDateTime: 2013-05-03 14:00:00
endDateTime: 2013-05-03 15:00:00
abstract: 
Storytelling is essential for communicating ideas. When they are well told, stories help us make sense of information, appreciate cultural or societal differences, and imagine living in entirely different worlds. Audio/visual stories in the form of radio programs, books-on-tape, podcasts, television, movies and animations, are especially powerful because they provide a richtisensory experience. Technological advances have made it easy to capturies using the microphones and cameras that are readily available in our mobile devices, but, the raw media rarelelling The best storytellers carefully compose, filter, edit and highlight the raw media to produce an engaging piece. Yet, the software tools they use to create and manipulate the raw audio/video media (e.g. Pro Tools, Photoshop, Premiere, Final Cut Pro, Maya etc.) force storytellers to work at a tediously low-level  selecting, filtering and layering pixels or cutting and transitioning between audio/video frames. While these tools provide flexible and precise control over the look and sound of the final result, they are notoriously difficult to learn and accessible primarily to experts. In this talk I'll present a number of recent projects that aim to significantly reduce the effort required to edit and produce high-quality audio/visual stories
bio: 
Maneesh Agrawala is an Associate Professor in Electrical Engineering and Computer Science at the University of California, Berkeley where he works on problems in visualization, computer graphics and human computer interaction. 

His focus is on investigating how cognitive design principles can be used to improve the effectiveness of visual displays. He received the SIGGRAPH Significant New Researcher award in 2008 and a MacArthur Foundation Fellowship in 2009.
locationRoomNumber: Room 2117
eventWebsite: https://talks.cs.umd.edu/talks/344
title: Storytelling Tools
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777329
speaker: Di-Wei Huang
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-03 14:30:00
endDateTime: 2013-05-03 16:00:00
abstract: 

Self-Organizing Maps (SOMs), inspired by maps of the external world that are formed in cortical regions of the brain, have been extensively used in visualizing high dimensional data. They exhibit the ability to discover, through unsupervised learning, non-linear projections to low dimensional (mostly 2-D) spaces that well preserve the relative relations of the original data. In the past, SOMs have generally been used to process static data, until more recently when they have been modified to handle temporal sequences. However, their computational applications are still limited by the fact that they mostly operate in isolation rather than being organized into architectures with multiple SOMs that can take advantage of their combined computing power. Therefore, I propose to build a multi-SOM system for processing multiple correlated temporal sequences. To achieve this goal, it is essential that the internal representations for each SOM be enriched beyond local and static representations, currently the mainstream encoding scheme for SOMs, so as to increase the amount and the robustness of information conveyed between SOMs, and to reduce timing requirement for reading neural activities of SOMs. In preliminary work, a type of spatiotemporal representation based on limit cycle attractors, rather than the usual static activity patterns, is studied with one-shot, multi-winner, and locally recurrent SOMs. This encoding scheme aims to both increase the expressiveness of SOMs' activity states and to reduce the precise timing requirements for accessing representations. The results identify conditions necessary to obtain limit cycles, and show that limit cycles are promising in terms of robustness and ability to serve as internal representations of temporal data. Accordingly, the proposed research plan includes investigating the effects of different architectural constructs for SOMs using limit cycle representations, building a multi-SOM system for processing multiple temporal sequences, and developing an adaptive control mechanism for the resultant system.
Examining Committee: 
Dr. James Reggia -  Chair 
Dr. Rance Cleaveland -  Deps Representative
Dr. Donald Perlis -  Committee Member
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/329
title: PhD Proposal: Multi-Self Organizing Map Architectures for Temporal Sequence Processing Based on Limit Cycle Attractors
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777335
speaker: Ashwin Kumar Kayyoor
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-06 10:00:00
endDateTime: 2013-05-06 11:30:00
abstract: 

The rapid increase in the data volumes encountered in many application domains has led to widespread adoption of parallel and distributed data management systems like parallel databases and MapReduce-based frameworks (e.g., Hadoop) in recent years. Use of such parallel or distributed frameworks is expected to accelerate in the coming years, putting further strain on already-scarce resources like compute power, network bandwidth, and energy. For reducing total execution times, there is a trend towards increasing the execution parallelism by spreading out data across a large number of machines. However, this often increases the total resource consumption, and especially energy consumption, significantly. In my dissertation research, I propose to develop data management techniques that minimize resource consumption through workload consolidation.
In the first part of my proposal, I focus on analytical workloads, consisting of read-only queries, being executed across a large number of machines. I argue that, for such workloads, minimizing the query latencies may not be critically important since the queries are often not run in an interactive mode. Instead, I propose that we should aim for reducing the total resource consumption by decreasing the degree of single-query execution parallelism, i.e., by trying to reduce the number of machines involved in the execution of a query (called query span). To that end, I propose workload-driven replica selection and placement algorithms that attempt to minimize the average query span by exploiting the fact that most distributed environments need to use replication for fault tolerance. Preliminary experiments show that judicious data placement and replication can dramatically reduce the average query spans resulting in significant reductions in the resource consumption.
In the second part of my proposal, I propose and study an in-memory MapReduce system optimized for performing complex analytics tasks on input data sizes that fit in a single machine's memory. I argue that systems like Hadoop that are designed to operate across a large number of machines are not optimal in performance for small and medium sized complex analytics tasks because of high startup costs, heavy disk activity, and wasteful checkpointing. I propose developing a prototype runtime called Hone that is both API and binary compatible with standard (distributed) Hadoop. In other words, we can take an existing Hadoop jar and run it, without modification, on a multi-core shared memory machine. This allows us to take existing Hadoop algorithms and find the most suitable runtime environment for execution on datasets of varying sizes.
Finally, I conclude the proposal with the future work I plan to pursue, which is divided into three parts: (a) supporting iterative algorithms in Hone, (b) supporting streaming analytics in Hone, and (c) workload-aware optimization of MapReduce workloads.
Examining Committee:
Dr. Amol Deshpande -  Chair
Dr. Alan Sussman -  Deps Representative
Dr. Jimmy Lin -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/335
title: PhD Proposal: Minimizing Resource Consumption through Consolidation in  Large-Scale Data Analysis Platforms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777337
speaker: Wenchao Zhou
speakerAffiliation: Department of Computer Science at Georgetown University
speakerUrl: http://www.cis.upenn.edu/~wenchaoz/
startDateTime: 2013-05-07 14:00:00
endDateTime: 2013-05-07 15:00:00
abstract: 

Operators of distributed systems often find themselves needing to answer forensic questions, in order to perform a variety of managerial tasks including fault detection, system debugging, accountability enforcement, and attack analysis.In thistalk, we will introduce Secure Network Provenance (SNP), an approach that provides the fundamental functionality required for answering such forensic questions -- the capability to "explain'' the existence (or change) of a certain distributed system state in a potentially adversarial environment.

We modelprovenance maintenance and querying as recursive queries over distributed relations, and propose security extensions toallow operators to reliably query provenanceinformation in adversarial environments. The extensions guarantee thatoperators can eventually detect the presence of compromised nodes thatlie or falsely implicate correct nodes.Finally, we discuss our work in the context of our longer term vision towardsprovably secure distributed systems.
bio: 

Wenchao Zhou is an Assistant Professor in the Department of Computer Science at Georgetown University.His research interests center on the use ofdata-centricandformal techniquestowards ensuringsafe and secure distributed systems. Dr. Zhou received the BSE degree in computer science from Tsinghua University in 2006, and the MSE and PhD degrees in computer science both from the University of Pennsylvania in 2009 and 2012 respectively.
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/337
title: Finding Needles in a Haystack: Secure Provenance in Distributed Systems
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777338
speaker: Nima Asadi
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-08 09:00:00
endDateTime: 2013-05-08 11:00:00
abstract: 

In recent years we have witnessed the growing popularity of social media among Internet users. The integration of social media in a variety of online services, together with the spread of smart phones, has changed the way we gossip, advertise, engage in political debates, and track public health. Social media and the online presence of news organizations have similarly revolutionized how news is created, distributed, and accessed. These changes, in turn, have brought about increasing engagement and contribution of users on the web, thereby making the web more dynamic.  A more dynamic web presents new challenges for web searchan important application of Information Retrieval (IR). A stream of new documents in various forms constantly flows into the web at a very high rate, adding to the old content. In many cases, documents quickly lose their relevance. In these time-sensitive environments, finding relevant content in response to user queries requires a real-time search service. This means that the search service must guarantee immediate availability of new content for search. In addition, the search service must offer a fastyet effectiveranking of documents, which requires an optimized search architecture. These aspects of todays web are at odds with how academic IR researchers have traditionally viewed the web, as a collection of static documents. Moreover, search architectures have received little attention in the IR literature. As a result, academic IR research, for the most part, does not provide a mechanism to efficiently handle a high-velocity stream of documents, nor does it facilitate real- time ranking.  In order to resolve these shortcomings, we need to adapt existing search architectures to the new characteristics of the web. To this end, this dissertation addresses the issues of real-time indexing and explores various search architectures for document ranking. We present an efficient mechanism to index a stream of documents in real-time, thereby enabling immediate availability of content for search. Our index structure works entirely in main memory and provides a mechanism to control inverted list contiguity, thereby enabling faster retrieval. Additionally, we consider document ranking with a machine-learned model, dubbed Learning to Rank (LTR), and introduce a novel multi-stage search architecture that enables fast retrieval and allows for more design flexibility. The stages of our architecture include candidate generation (top-k retrieval), feature extraction, and document re-ranking using tree-based LTR models. We compare this architecture with a traditional monolithic architecture where candidate generation and feature extraction occur simultaneously. As we lay out our multi-stage search architecture, we present optimizations to each stage to facilitate low-latency ranking. These optimizations include a fast approximate algorithm to retrieve top k documents that are potentially most relevant to an input query, document vector organizations for feature extraction, architecture-conscious implementations of tree ensembles for LTR using predication and vectorization, and algorithms to train tree-based LTR models that are fast to evaluate. We also study the efficiency-effectiveness tradeoffs of these techniques, and empirically evaluate our end-to-end architecture on microblog document collections.  As we argue in this work, the techniques from this dissertation can improve the efficiency of search for users without degrading search quality. As web becomes even more dynamic and information continues to be disseminated in real-time, adapting search services to conform to real-time settings will become ever more important. 
Examining Committee:
Committee Chair: Dr. Jimmy Lin
Dean's Representative: Dr. Carol Y. Espy-Wilson
Committee Members:  Dr. Hal Daume III
 Dr. Amol Deshpande
 Dr. Alan Sussman
bio: 
locationRoomNumber: 4185
eventWebsite: https://talks.cs.umd.edu/talks/338
title: PhD Defense: Multi-Stage Search Architectures for Streaming Documents
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777346
speaker: Qi Hu
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-10 10:00:00
endDateTime: 2013-05-10 12:00:00
abstract: 

The $N$-body problem appears in many computational physics simulations. At each time step the computation involves an all-pairs sum whose complexity is quadratic, followed by an update of particle positions. This cost means that it is not practical to solve such dynamic $N$-body problems on large scale. To improve this situation, we use both algorithmic and hardware approaches. Our algorithmic approach is to use the Fast Multipole Method (FMM), which is a divide-and-conquer algorithm that performs a fast $N$-body sum using a spatial decomposition and is often used in a time-stepping or iterative loop, to reduce such quadratic complexity to linear with guaranteed accuracy. Our hardware approach is to use heterogeneous clusters, which comprised of nodes that contain multi-core CPUs tightly coupled with accelerators, such as graphics processors unit (GPU) as our underline parallel processing hardware, on which efficient implementations require highly non-trivial re-designed algorithms.   In this dissertation, we fundamentally reconsider the FMM algorithms on heterogeneous architectures to achieve a significant improvement over recent/previous implementations in literature and to make the algorithm ready for use as a workhorse simulation tool for both time-dependent vortex flow problems and for boundary element methods. Our major contributions include: 
1. Novel FMM data structures using parallel construction algorithms for dynamic problems. 
2. A fast hetegenenous FMM algorithm for both single and multiple computing nodes. 
3. An efficient inter-node communication management using fast parallel data structures. 
4. A scalable FMM algorithm using novel Helmholz decomposition for Vortex Methods (VM).  The proposed algorithms can handle non-uniform distributions with irregular partition shapes to achieve workload balance and their MPI-CUDA implementations are highly tuned up and demonstrate the state of the art performances. 
Examining Committee:
Committee Chair: Dr. Ramani Duraiswami
Co-Chair :  Dr. Nail A. Gumerov
Dean's Representative: Dr. J. Gordon Leishman
 Dr. David Mount
 Dr. Howard Elman
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/346
title: PhD Defense: Scalable Fast Multipole Methods on Heterogeneous Architecture
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
id: 777284
speaker: ALex Slivkins
speakerAffiliation: Microsoft Research Silicon Valley  Mountain View
speakerUrl: research.microsoft.com/en-us/people/slivkins/
startDateTime: 2013-05-10 13:00:00
endDateTime: 2013-05-10 14:00:00
abstract: 
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/284
title: to be announced
locationName: 
facilId: 19191919
buildingAbbreviation: 
buildingUrl: 
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777334
speaker: Christoph Koch
speakerAffiliation: EPFL
speakerUrl: http://people.epfl.ch/christoph.koch
startDateTime: 2013-05-13 11:00:00
endDateTime: 2013-05-13 12:00:00
abstract: 



In this talk, I present a system for the automatic synthesis of efficient algorithms specialized for a particular memory hierarchy and a set of storage devices. The developer provides two independent inputs: 1) an algorithm that ignores memory hierarchy and external storage aspects; and 2) a description of the target memory hierarchy, including its topology and parameters. Our system is able to automatically synthesize memory-hierarchy and storage-device-aware algorithms out of those specifications, for tasks such as joins and sorting. The framework is extensible and allows developers to quickly synthesize custom out-of-core algorithms as new storage technologies become available.
bio: 

Christoph Koch is a professor of Computer Science at EPFL, specializing in data management. Until 2010, he was an Associate Professor in the Department of Computer Science at Cornell University. Previously to this, from 2005 to 2007, he was an Associate Professor of Computer Science at Saarland University. Earlier, he obtained his PhD in Artificial Intelligence from TU Vienna and CERN (2001), was a postdoctoral researcher at TU Vienna and the University of Edinburgh (2001-2003), and an assistant professor at TU Vienna (2003-2005). He obtained his Habilitation degree in 2004.He has won Best Paper Awards at PODS 2002, ICALP 2005, and SIGMOD 2011, an Outrageous Ideas and Vision Paper Award at CIDR 2013, a Google Research Award (in 2009), and an ERC Grant (in 2011). He is a PI of the Billion-Euro EUFET Flagship Human Brain Project. He (co-)chaired the program committees of DBPL 2005, WebDB 2008, and ICDE 2011, and was PC vice-chair of ICDE 2008 and ICDE 2009. He has served on the editorial board of ACM Transactions on Internet Technology as well as in numerous program committees.He currently serves as PC co-chair of VLDB 2013 and Editor-in-Chief of PVLDB.
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/334
title: Automatic Synthesis of Out-of-Core Algorithms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777340
speaker: John Alexis Guerra Gomez
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-13 12:00:00
endDateTime: 2013-05-13 14:00:00
abstract: 

Hierarchies are a useful way of representing data. The parent-to-child relationships they define facilitate the analysis of a dataset by breaking it down into its component parts. Representing data as hierarchies can also be used to track changes to a dataset over time or between versions. For example, analysts can use hierarchies to uncover changes in the US Federal Budget in the last twenty years, by grouping accounts by Agencies and Bureaus. Similarly, a company manager can analyze changes to their product sales due to the holiday season by breaking them up by markets and product categories. Exploring differences in such trees could help them understand changes in the data. However, comparing hierarchies is a difficult task, even when comparing two trees with a small number of nodes. To address this, I used information visualization techniques to support data comparison tasks using hierarchies. After evaluating my techniques with domain experts on real world problems, I identified and addressed two main research topics:  First, I tackled the problem of comparing two versions of a tree by using two types of change, while most of the significant work on this topic has focused only on changes in node values or changes in topology. TreeVersity (http://hcil.cs.umd.edu/treeversity) is a comparison tool that allows users to explore changes between two versions of a tree by tracking node value differences, and newly created or removed nodes. Domain experts using TreeVersity were excited to discover differences in the trees, but expressed a desire to explore the evolution of a dataset over time. To that end, they suggested to apply TreeVersity comparison capabilities to non inherently hierarchical datasets.  Thus, I then addressed the problem of exploring changes over time in datasets that can be categorized as trees. TreeVersity2 (http://treeversity.cattlab.umd.edu is a web-based data comparison tool that allows users to explore a tree that change over time and of datasets that are not inherently hierarchical, by categorizing them by its attributes. TreeVersity2 also helps users navigate the sometimes large amounts of differences between versions of a tree using an interactive textual reporting tool.  My research has resulted in two main contributions: First, the introduction of the Bullet, a visualization glyph to represent four characteristics of change (as described in Section [sec:Contributions]) in tree nodes, and the implementation of the Bullet in TreeVersity. Second, the creation of the StemView, a tree visualization technique that represents five characteristics of change in all the nodes of a tree (not just the leaves), and the implementation of the StemView in TreeVersity2. Furthermore, my research resulted in the development of the reporting tool, another feature of TreeVersity2, which helps users navigate outstanding changes in the tree with textual representations and coordinated interactions. Moreover, these developments have been tested in 13 case studies with domain experts on real world comparison problems. The case studies have validated the utility and flexibility of my approaches. Finally, my research opens possibilities for future research on comparing hierarchical structures. 
Examining Committee:
Committee Chair: Dr. Ben Shneiderman
Dean's Representative: Dr. David Lovell
Committee Members:  Dr. Catherine Plaisant
 Dr. Lise Getoor
 Dr. Ben Bederson
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/340
title: PhD Defense: Exploring Differences in Multivariate Datasets Using Hierarchies:  An Interactive Information Visualization Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777341
speaker: Jochen Koenemann
speakerAffiliation: Associate Professor, University of Waterloo 
speakerUrl: http://www.math.uwaterloo.ca/~jochen/
startDateTime: 2013-05-13 13:00:00
endDateTime: 2013-05-13 14:00:00
abstract: The first part of this talk focuses on a network diffusion model that was recently introduced by Goldberg  Liu (SODA'13). Goldberg  Liu's model adapts the earlier linear threshold model of Kempe, Kleinberg  Tardos (KDD'03) in an effort to capture aspects of technology adaptation processes in networks. We present new, improved, yet simple algorithms for the so called Influence Maximization problem in this setting.
A key component of our algorithm is a Langrangean multiplier preserving (LMP) algorithm for the Prize-collecting Node-weighted Steiner Tree problem (PC-NWST). This problem had been studied in prior work by Moss and Rabani (STOC'01  SICOMP'07) who presented a primal-dual O(log |V|) approximate and LMP algorithm, and showed that this is best possible unless NP=P.
We demonstrate that Moss  Rabani's algorithm for PC-NWST is seriously flawed. We then present a new, fundamentally different primal-dual method achieving the same performance guarantee. Our algorithm introduces several novel features to the primal-dual method that may be of independent interest.
Joint work with Laura Sanita and Sina Sadeghian
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/341
title: Network Diffusion & Node-Weighted Steiner Trees
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777345
speaker: Vahid Liaghat
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-14 09:30:00
endDateTime: 2013-05-14 11:00:00
abstract: 

An offline algorithm is one that knows the entire input in advance. An online algorithm, however, processes its input in a serial fashion. In contrast to offline algorithms, an online algorithm works in a local fashion and has to make irrevocable decisions without having the entire input. Online algorithms are often not optimal since their irrevocable decisions may turn out to be inefficient after receiving the rest of the input. For a given online problem, the goal is to design algorithms which are competitive against the offline optimal solutions.  We study the competitive analysis of fundamental problems in the literature such as online matching, online Steiner connectivity, and the k-server problem. Although there are many generic tools for solving an optimization problem in the offline paradigm, much less is known for tackling online problems. A representative example is bipartite matching. Even though bipartite matching is easily computable in the offline setting, solving the problem online is shown to be very challenging. The main focus of our work is to design generic techniques for solving linear optimization problems where the solution space is restricted via a set of linear constraints. A general family of these problems are online packing/covering problems. Our work so far shows that for several seemingly unrelated problems, primal-dual techniques can be successfully applied as a unifying approach for solving these problems. We believe this leads to generic algorithmic frameworks for solving online problems.  In this proposal, we first show the effectiveness of our techniques for both adversarial settings and stochastic settings. In particular, we introduce new techniques for solving two online linear optimization problems, namely, the stochastic generalized assignment problem and the network design problems characterized by proper functions. The former belongs to the family of online packing problems while the later belongs to the family of online covering problems. We next describe the challenges ahead for venturing deeper into either of these major families of problems.
Examining Committee:
Dr. Mohammad Taghi Hajiaghayi -  Chair
Dr. Hector Corrado Bravo -  Deps Representative
Dr. Aravind Srinivasan -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/345
title: PhD Proposal: Online Algorithms with the Uncertainty of Future, A Primal-Dual Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777342
speaker: Panos Chrysanthis
speakerAffiliation: University of Pittsburgh
speakerUrl: http://panos.cs.pitt.edu/
startDateTime: 2013-05-14 11:00:00
endDateTime: 2013-05-14 12:00:00
abstract: TBA
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/342
title: TBA
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777347
speaker: Jeff Stuckman
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-16 13:00:00
endDateTime: 2013-05-16 14:30:00
abstract: 

Security vulnerabilities, or defects in programs that enable their security to be breached, frequently facilitate successful attacks against systems. While software quality metrics to predict defects have been proposed and evaluated in the past, less is known about the performance of security metrics in predicting vulnerabilities and the contexts in which they are effective. In the proposed research, we build a corpus of security vulnerabilities from open-source software, propose security metrics for software artifacts, and empirically evaluate them with respect to current quality and security metrics. 
We build a diverse, representative corpus of vulnerabilities in web applications, storing them in a structured format which links defect information with their relevant source code locations. This corpus will be used to measure the vulnerability prediction performance of traditional metric suites, using processes that avoid confounding variables to which other testing methods are prone. We will then propose, adapt, and evaluate metrics which quantify security-related characteristics such as attack surface, exposure, and privilege, utilizing an established theoretical evaluation method to study these metrics properties.
One product of this research is a substantial corpus of security vulnerabilities, which will become available to the research community to facilitate empirical studies of vulnerabilities and security hardening techniques. Another outcome of this research is unified, comparative data on the vulnerability prediction performance of traditional quality metrics and security-specific metrics, some of which are new or otherwise have not been evaluated. These results are enabled by the application of theoretical and empirical validation methods to attack surface metrics, which have not yet been examined in this way. Finally, this research will produce measurement tools for developers and testers, allowing security metrics to be leveraged for tasks such as estimating the relative security risks of programs or portions of programs, prioritizing code reviews or defense-in-depth measures for specific components, and assessing the security impact of adding a new component
Examining Committee:
Dr. James Purtilo -  Chair
Dr. James Reggia -  Deps Representative
Dr. Michael Hicks -  Committee Member
bio: 
locationRoomNumber: 4103
eventWebsite: https://talks.cs.umd.edu/talks/347
title: PhD Proposal: Developing and Validating Security Vulnerability Indicator Metrics
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-03 08:57:18
id: 777332
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-22 08:30:00
endDateTime: 2013-05-22 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/332
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777333
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-23 08:30:00
endDateTime: 2013-05-23 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/333
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-03 08:57:18
Info: Event is already in the database
id: 777335
speaker: Ashwin Kumar Kayyoor
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-06 10:00:00
endDateTime: 2013-05-06 11:30:00
abstract: 

The rapid increase in the data volumes encountered in many application domains has led to widespread adoption of parallel and distributed data management systems like parallel databases and MapReduce-based frameworks (e.g., Hadoop) in recent years. Use of such parallel or distributed frameworks is expected to accelerate in the coming years, putting further strain on already-scarce resources like compute power, network bandwidth, and energy. For reducing total execution times, there is a trend towards increasing the execution parallelism by spreading out data across a large number of machines. However, this often increases the total resource consumption, and especially energy consumption, significantly. In my dissertation research, I propose to develop data management techniques that minimize resource consumption through workload consolidation.
In the first part of my proposal, I focus on analytical workloads, consisting of read-only queries, being executed across a large number of machines. I argue that, for such workloads, minimizing the query latencies may not be critically important since the queries are often not run in an interactive mode. Instead, I propose that we should aim for reducing the total resource consumption by decreasing the degree of single-query execution parallelism, i.e., by trying to reduce the number of machines involved in the execution of a query (called query span). To that end, I propose workload-driven replica selection and placement algorithms that attempt to minimize the average query span by exploiting the fact that most distributed environments need to use replication for fault tolerance. Preliminary experiments show that judicious data placement and replication can dramatically reduce the average query spans resulting in significant reductions in the resource consumption.
In the second part of my proposal, I propose and study an in-memory MapReduce system optimized for performing complex analytics tasks on input data sizes that fit in a single machine's memory. I argue that systems like Hadoop that are designed to operate across a large number of machines are not optimal in performance for small and medium sized complex analytics tasks because of high startup costs, heavy disk activity, and wasteful checkpointing. I propose developing a prototype runtime called Hone that is both API and binary compatible with standard (distributed) Hadoop. In other words, we can take an existing Hadoop jar and run it, without modification, on a multi-core shared memory machine. This allows us to take existing Hadoop algorithms and find the most suitable runtime environment for execution on datasets of varying sizes.
Finally, I conclude the proposal with the future work I plan to pursue, which is divided into three parts: (a) supporting iterative algorithms in Hone, (b) supporting streaming analytics in Hone, and (c) workload-aware optimization of MapReduce workloads.
Examining Committee:
Dr. Amol Deshpande -  Chair
Dr. Alan Sussman -  Deps Representative
Dr. Jimmy Lin -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/335
title: PhD Proposal: Minimizing Resource Consumption through Consolidation in  Large-Scale Data Analysis Platforms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777337
speaker: Wenchao Zhou
speakerAffiliation: Department of Computer Science at Georgetown University
speakerUrl: http://www.cis.upenn.edu/~wenchaoz/
startDateTime: 2013-05-07 14:00:00
endDateTime: 2013-05-07 15:00:00
abstract: 

Operators of distributed systems often find themselves needing to answer forensic questions, in order to perform a variety of managerial tasks including fault detection, system debugging, accountability enforcement, and attack analysis.In thistalk, we will introduce Secure Network Provenance (SNP), an approach that provides the fundamental functionality required for answering such forensic questions -- the capability to "explain'' the existence (or change) of a certain distributed system state in a potentially adversarial environment.

We modelprovenance maintenance and querying as recursive queries over distributed relations, and propose security extensions toallow operators to reliably query provenanceinformation in adversarial environments. The extensions guarantee thatoperators can eventually detect the presence of compromised nodes thatlie or falsely implicate correct nodes.Finally, we discuss our work in the context of our longer term vision towardsprovably secure distributed systems.
bio: 

Wenchao Zhou is an Assistant Professor in the Department of Computer Science at Georgetown University.His research interests center on the use ofdata-centricandformal techniquestowards ensuringsafe and secure distributed systems. Dr. Zhou received the BSE degree in computer science from Tsinghua University in 2006, and the MSE and PhD degrees in computer science both from the University of Pennsylvania in 2009 and 2012 respectively.
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/337
title: Finding Needles in a Haystack: Secure Provenance in Distributed Systems
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777338
speaker: Nima Asadi
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-08 09:00:00
endDateTime: 2013-05-08 11:00:00
abstract: 

In recent years we have witnessed the growing popularity of social media among Internet users. The integration of social media in a variety of online services, together with the spread of smart phones, has changed the way we gossip, advertise, engage in political debates, and track public health. Social media and the online presence of news organizations have similarly revolutionized how news is created, distributed, and accessed. These changes, in turn, have brought about increasing engagement and contribution of users on the web, thereby making the web more dynamic.  A more dynamic web presents new challenges for web searchan important application of Information Retrieval (IR). A stream of new documents in various forms constantly flows into the web at a very high rate, adding to the old content. In many cases, documents quickly lose their relevance. In these time-sensitive environments, finding relevant content in response to user queries requires a real-time search service. This means that the search service must guarantee immediate availability of new content for search. In addition, the search service must offer a fastyet effectiveranking of documents, which requires an optimized search architecture. These aspects of todays web are at odds with how academic IR researchers have traditionally viewed the web, as a collection of static documents. Moreover, search architectures have received little attention in the IR literature. As a result, academic IR research, for the most part, does not provide a mechanism to efficiently handle a high-velocity stream of documents, nor does it facilitate real- time ranking.  In order to resolve these shortcomings, we need to adapt existing search architectures to the new characteristics of the web. To this end, this dissertation addresses the issues of real-time indexing and explores various search architectures for document ranking. We present an efficient mechanism to index a stream of documents in real-time, thereby enabling immediate availability of content for search. Our index structure works entirely in main memory and provides a mechanism to control inverted list contiguity, thereby enabling faster retrieval. Additionally, we consider document ranking with a machine-learned model, dubbed Learning to Rank (LTR), and introduce a novel multi-stage search architecture that enables fast retrieval and allows for more design flexibility. The stages of our architecture include candidate generation (top-k retrieval), feature extraction, and document re-ranking using tree-based LTR models. We compare this architecture with a traditional monolithic architecture where candidate generation and feature extraction occur simultaneously. As we lay out our multi-stage search architecture, we present optimizations to each stage to facilitate low-latency ranking. These optimizations include a fast approximate algorithm to retrieve top k documents that are potentially most relevant to an input query, document vector organizations for feature extraction, architecture-conscious implementations of tree ensembles for LTR using predication and vectorization, and algorithms to train tree-based LTR models that are fast to evaluate. We also study the efficiency-effectiveness tradeoffs of these techniques, and empirically evaluate our end-to-end architecture on microblog document collections.  As we argue in this work, the techniques from this dissertation can improve the efficiency of search for users without degrading search quality. As web becomes even more dynamic and information continues to be disseminated in real-time, adapting search services to conform to real-time settings will become ever more important. 
Examining Committee:
Committee Chair: Dr. Jimmy Lin
Dean's Representative: Dr. Carol Y. Espy-Wilson
Committee Members:  Dr. Hal Daume III
 Dr. Amol Deshpande
 Dr. Alan Sussman
bio: 
locationRoomNumber: 4185
eventWebsite: https://talks.cs.umd.edu/talks/338
title: PhD Defense: Multi-Stage Search Architectures for Streaming Documents
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777346
speaker: Qi Hu
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-10 10:00:00
endDateTime: 2013-05-10 12:00:00
abstract: 

The $N$-body problem appears in many computational physics simulations. At each time step the computation involves an all-pairs sum whose complexity is quadratic, followed by an update of particle positions. This cost means that it is not practical to solve such dynamic $N$-body problems on large scale. To improve this situation, we use both algorithmic and hardware approaches. Our algorithmic approach is to use the Fast Multipole Method (FMM), which is a divide-and-conquer algorithm that performs a fast $N$-body sum using a spatial decomposition and is often used in a time-stepping or iterative loop, to reduce such quadratic complexity to linear with guaranteed accuracy. Our hardware approach is to use heterogeneous clusters, which comprised of nodes that contain multi-core CPUs tightly coupled with accelerators, such as graphics processors unit (GPU) as our underline parallel processing hardware, on which efficient implementations require highly non-trivial re-designed algorithms.   In this dissertation, we fundamentally reconsider the FMM algorithms on heterogeneous architectures to achieve a significant improvement over recent/previous implementations in literature and to make the algorithm ready for use as a workhorse simulation tool for both time-dependent vortex flow problems and for boundary element methods. Our major contributions include: 
1. Novel FMM data structures using parallel construction algorithms for dynamic problems. 
2. A fast hetegenenous FMM algorithm for both single and multiple computing nodes. 
3. An efficient inter-node communication management using fast parallel data structures. 
4. A scalable FMM algorithm using novel Helmholz decomposition for Vortex Methods (VM).  The proposed algorithms can handle non-uniform distributions with irregular partition shapes to achieve workload balance and their MPI-CUDA implementations are highly tuned up and demonstrate the state of the art performances. 
Examining Committee:
Committee Chair: Dr. Ramani Duraiswami
Co-Chair :  Dr. Nail A. Gumerov
Dean's Representative: Dr. J. Gordon Leishman
 Dr. David Mount
 Dr. Howard Elman
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/346
title: PhD Defense: Scalable Fast Multipole Methods on Heterogeneous Architecture
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777284
speaker: ALex Slivkins
speakerAffiliation: Microsoft Research Silicon Valley  Mountain View
speakerUrl: research.microsoft.com/en-us/people/slivkins/
startDateTime: 2013-05-10 13:00:00
endDateTime: 2013-05-10 14:00:00
abstract: 
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/284
title: to be announced
locationName: 
facilId: 19191919
buildingAbbreviation: 
buildingUrl: 
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777334
speaker: Christoph Koch
speakerAffiliation: EPFL
speakerUrl: http://people.epfl.ch/christoph.koch
startDateTime: 2013-05-13 11:00:00
endDateTime: 2013-05-13 12:00:00
abstract: 



In this talk, I present a system for the automatic synthesis of efficient algorithms specialized for a particular memory hierarchy and a set of storage devices. The developer provides two independent inputs: 1) an algorithm that ignores memory hierarchy and external storage aspects; and 2) a description of the target memory hierarchy, including its topology and parameters. Our system is able to automatically synthesize memory-hierarchy and storage-device-aware algorithms out of those specifications, for tasks such as joins and sorting. The framework is extensible and allows developers to quickly synthesize custom out-of-core algorithms as new storage technologies become available.
bio: 

Christoph Koch is a professor of Computer Science at EPFL, specializing in data management. Until 2010, he was an Associate Professor in the Department of Computer Science at Cornell University. Previously to this, from 2005 to 2007, he was an Associate Professor of Computer Science at Saarland University. Earlier, he obtained his PhD in Artificial Intelligence from TU Vienna and CERN (2001), was a postdoctoral researcher at TU Vienna and the University of Edinburgh (2001-2003), and an assistant professor at TU Vienna (2003-2005). He obtained his Habilitation degree in 2004.He has won Best Paper Awards at PODS 2002, ICALP 2005, and SIGMOD 2011, an Outrageous Ideas and Vision Paper Award at CIDR 2013, a Google Research Award (in 2009), and an ERC Grant (in 2011). He is a PI of the Billion-Euro EUFET Flagship Human Brain Project. He (co-)chaired the program committees of DBPL 2005, WebDB 2008, and ICDE 2011, and was PC vice-chair of ICDE 2008 and ICDE 2009. He has served on the editorial board of ACM Transactions on Internet Technology as well as in numerous program committees.He currently serves as PC co-chair of VLDB 2013 and Editor-in-Chief of PVLDB.
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/334
title: Automatic Synthesis of Out-of-Core Algorithms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777340
speaker: John Alexis Guerra Gomez
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-13 12:00:00
endDateTime: 2013-05-13 14:00:00
abstract: 

Hierarchies are a useful way of representing data. The parent-to-child relationships they define facilitate the analysis of a dataset by breaking it down into its component parts. Representing data as hierarchies can also be used to track changes to a dataset over time or between versions. For example, analysts can use hierarchies to uncover changes in the US Federal Budget in the last twenty years, by grouping accounts by Agencies and Bureaus. Similarly, a company manager can analyze changes to their product sales due to the holiday season by breaking them up by markets and product categories. Exploring differences in such trees could help them understand changes in the data. However, comparing hierarchies is a difficult task, even when comparing two trees with a small number of nodes. To address this, I used information visualization techniques to support data comparison tasks using hierarchies. After evaluating my techniques with domain experts on real world problems, I identified and addressed two main research topics:  First, I tackled the problem of comparing two versions of a tree by using two types of change, while most of the significant work on this topic has focused only on changes in node values or changes in topology. TreeVersity (http://hcil.cs.umd.edu/treeversity) is a comparison tool that allows users to explore changes between two versions of a tree by tracking node value differences, and newly created or removed nodes. Domain experts using TreeVersity were excited to discover differences in the trees, but expressed a desire to explore the evolution of a dataset over time. To that end, they suggested to apply TreeVersity comparison capabilities to non inherently hierarchical datasets.  Thus, I then addressed the problem of exploring changes over time in datasets that can be categorized as trees. TreeVersity2 (http://treeversity.cattlab.umd.edu is a web-based data comparison tool that allows users to explore a tree that change over time and of datasets that are not inherently hierarchical, by categorizing them by its attributes. TreeVersity2 also helps users navigate the sometimes large amounts of differences between versions of a tree using an interactive textual reporting tool.  My research has resulted in two main contributions: First, the introduction of the Bullet, a visualization glyph to represent four characteristics of change (as described in Section [sec:Contributions]) in tree nodes, and the implementation of the Bullet in TreeVersity. Second, the creation of the StemView, a tree visualization technique that represents five characteristics of change in all the nodes of a tree (not just the leaves), and the implementation of the StemView in TreeVersity2. Furthermore, my research resulted in the development of the reporting tool, another feature of TreeVersity2, which helps users navigate outstanding changes in the tree with textual representations and coordinated interactions. Moreover, these developments have been tested in 13 case studies with domain experts on real world comparison problems. The case studies have validated the utility and flexibility of my approaches. Finally, my research opens possibilities for future research on comparing hierarchical structures. 
Examining Committee:
Committee Chair: Dr. Ben Shneiderman
Dean's Representative: Dr. David Lovell
Committee Members:  Dr. Catherine Plaisant
 Dr. Lise Getoor
 Dr. Ben Bederson
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/340
title: PhD Defense: Exploring Differences in Multivariate Datasets Using Hierarchies:  An Interactive Information Visualization Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777341
speaker: Jochen Koenemann
speakerAffiliation: Associate Professor, University of Waterloo 
speakerUrl: http://www.math.uwaterloo.ca/~jochen/
startDateTime: 2013-05-13 13:00:00
endDateTime: 2013-05-13 14:00:00
abstract: The first part of this talk focuses on a network diffusion model that was recently introduced by Goldberg  Liu (SODA'13). Goldberg  Liu's model adapts the earlier linear threshold model of Kempe, Kleinberg  Tardos (KDD'03) in an effort to capture aspects of technology adaptation processes in networks. We present new, improved, yet simple algorithms for the so called Influence Maximization problem in this setting.
A key component of our algorithm is a Langrangean multiplier preserving (LMP) algorithm for the Prize-collecting Node-weighted Steiner Tree problem (PC-NWST). This problem had been studied in prior work by Moss and Rabani (STOC'01  SICOMP'07) who presented a primal-dual O(log |V|) approximate and LMP algorithm, and showed that this is best possible unless NP=P.
We demonstrate that Moss  Rabani's algorithm for PC-NWST is seriously flawed. We then present a new, fundamentally different primal-dual method achieving the same performance guarantee. Our algorithm introduces several novel features to the primal-dual method that may be of independent interest.
Joint work with Laura Sanita and Sina Sadeghian
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/341
title: Network Diffusion & Node-Weighted Steiner Trees
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777345
speaker: Vahid Liaghat
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-14 09:30:00
endDateTime: 2013-05-14 11:00:00
abstract: 

An offline algorithm is one that knows the entire input in advance. An online algorithm, however, processes its input in a serial fashion. In contrast to offline algorithms, an online algorithm works in a local fashion and has to make irrevocable decisions without having the entire input. Online algorithms are often not optimal since their irrevocable decisions may turn out to be inefficient after receiving the rest of the input. For a given online problem, the goal is to design algorithms which are competitive against the offline optimal solutions.  We study the competitive analysis of fundamental problems in the literature such as online matching, online Steiner connectivity, and the k-server problem. Although there are many generic tools for solving an optimization problem in the offline paradigm, much less is known for tackling online problems. A representative example is bipartite matching. Even though bipartite matching is easily computable in the offline setting, solving the problem online is shown to be very challenging. The main focus of our work is to design generic techniques for solving linear optimization problems where the solution space is restricted via a set of linear constraints. A general family of these problems are online packing/covering problems. Our work so far shows that for several seemingly unrelated problems, primal-dual techniques can be successfully applied as a unifying approach for solving these problems. We believe this leads to generic algorithmic frameworks for solving online problems.  In this proposal, we first show the effectiveness of our techniques for both adversarial settings and stochastic settings. In particular, we introduce new techniques for solving two online linear optimization problems, namely, the stochastic generalized assignment problem and the network design problems characterized by proper functions. The former belongs to the family of online packing problems while the later belongs to the family of online covering problems. We next describe the challenges ahead for venturing deeper into either of these major families of problems.
Examining Committee:
Dr. Mohammad Taghi Hajiaghayi -  Chair
Dr. Hector Corrado Bravo -  Deps Representative
Dr. Aravind Srinivasan -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/345
title: PhD Proposal: Online Algorithms with the Uncertainty of Future, A Primal-Dual Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777342
speaker: Panos Chrysanthis
speakerAffiliation: University of Pittsburgh
speakerUrl: http://panos.cs.pitt.edu/
startDateTime: 2013-05-14 11:00:00
endDateTime: 2013-05-14 12:00:00
abstract: TBA
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/342
title: TBA
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777347
speaker: Jeff Stuckman
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-16 13:00:00
endDateTime: 2013-05-16 14:30:00
abstract: 

Security vulnerabilities, or defects in programs that enable their security to be breached, frequently facilitate successful attacks against systems. While software quality metrics to predict defects have been proposed and evaluated in the past, less is known about the performance of security metrics in predicting vulnerabilities and the contexts in which they are effective. In the proposed research, we build a corpus of security vulnerabilities from open-source software, propose security metrics for software artifacts, and empirically evaluate them with respect to current quality and security metrics. 
We build a diverse, representative corpus of vulnerabilities in web applications, storing them in a structured format which links defect information with their relevant source code locations. This corpus will be used to measure the vulnerability prediction performance of traditional metric suites, using processes that avoid confounding variables to which other testing methods are prone. We will then propose, adapt, and evaluate metrics which quantify security-related characteristics such as attack surface, exposure, and privilege, utilizing an established theoretical evaluation method to study these metrics properties.
One product of this research is a substantial corpus of security vulnerabilities, which will become available to the research community to facilitate empirical studies of vulnerabilities and security hardening techniques. Another outcome of this research is unified, comparative data on the vulnerability prediction performance of traditional quality metrics and security-specific metrics, some of which are new or otherwise have not been evaluated. These results are enabled by the application of theoretical and empirical validation methods to attack surface metrics, which have not yet been examined in this way. Finally, this research will produce measurement tools for developers and testers, allowing security metrics to be leveraged for tasks such as estimating the relative security risks of programs or portions of programs, prioritizing code reviews or defense-in-depth measures for specific components, and assessing the security impact of adding a new component
Examining Committee:
Dr. James Purtilo -  Chair
Dr. James Reggia -  Deps Representative
Dr. Michael Hicks -  Committee Member
bio: 
locationRoomNumber: 4103
eventWebsite: https://talks.cs.umd.edu/talks/347
title: PhD Proposal: Developing and Validating Security Vulnerability Indicator Metrics
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777332
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-22 08:30:00
endDateTime: 2013-05-22 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/332
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777333
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-23 08:30:00
endDateTime: 2013-05-23 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/333
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-04 08:57:18
Info: Event is already in the database
id: 777335
speaker: Ashwin Kumar Kayyoor
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-06 10:00:00
endDateTime: 2013-05-06 11:30:00
abstract: 

The rapid increase in the data volumes encountered in many application domains has led to widespread adoption of parallel and distributed data management systems like parallel databases and MapReduce-based frameworks (e.g., Hadoop) in recent years. Use of such parallel or distributed frameworks is expected to accelerate in the coming years, putting further strain on already-scarce resources like compute power, network bandwidth, and energy. For reducing total execution times, there is a trend towards increasing the execution parallelism by spreading out data across a large number of machines. However, this often increases the total resource consumption, and especially energy consumption, significantly. In my dissertation research, I propose to develop data management techniques that minimize resource consumption through workload consolidation.
In the first part of my proposal, I focus on analytical workloads, consisting of read-only queries, being executed across a large number of machines. I argue that, for such workloads, minimizing the query latencies may not be critically important since the queries are often not run in an interactive mode. Instead, I propose that we should aim for reducing the total resource consumption by decreasing the degree of single-query execution parallelism, i.e., by trying to reduce the number of machines involved in the execution of a query (called query span). To that end, I propose workload-driven replica selection and placement algorithms that attempt to minimize the average query span by exploiting the fact that most distributed environments need to use replication for fault tolerance. Preliminary experiments show that judicious data placement and replication can dramatically reduce the average query spans resulting in significant reductions in the resource consumption.
In the second part of my proposal, I propose and study an in-memory MapReduce system optimized for performing complex analytics tasks on input data sizes that fit in a single machine's memory. I argue that systems like Hadoop that are designed to operate across a large number of machines are not optimal in performance for small and medium sized complex analytics tasks because of high startup costs, heavy disk activity, and wasteful checkpointing. I propose developing a prototype runtime called Hone that is both API and binary compatible with standard (distributed) Hadoop. In other words, we can take an existing Hadoop jar and run it, without modification, on a multi-core shared memory machine. This allows us to take existing Hadoop algorithms and find the most suitable runtime environment for execution on datasets of varying sizes.
Finally, I conclude the proposal with the future work I plan to pursue, which is divided into three parts: (a) supporting iterative algorithms in Hone, (b) supporting streaming analytics in Hone, and (c) workload-aware optimization of MapReduce workloads.
Examining Committee:
Dr. Amol Deshpande -  Chair
Dr. Alan Sussman -  Deps Representative
Dr. Jimmy Lin -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/335
title: PhD Proposal: Minimizing Resource Consumption through Consolidation in  Large-Scale Data Analysis Platforms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777337
speaker: Wenchao Zhou
speakerAffiliation: Department of Computer Science at Georgetown University
speakerUrl: http://www.cis.upenn.edu/~wenchaoz/
startDateTime: 2013-05-07 14:00:00
endDateTime: 2013-05-07 15:00:00
abstract: 

Operators of distributed systems often find themselves needing to answer forensic questions, in order to perform a variety of managerial tasks including fault detection, system debugging, accountability enforcement, and attack analysis.In thistalk, we will introduce Secure Network Provenance (SNP), an approach that provides the fundamental functionality required for answering such forensic questions -- the capability to "explain'' the existence (or change) of a certain distributed system state in a potentially adversarial environment.

We modelprovenance maintenance and querying as recursive queries over distributed relations, and propose security extensions toallow operators to reliably query provenanceinformation in adversarial environments. The extensions guarantee thatoperators can eventually detect the presence of compromised nodes thatlie or falsely implicate correct nodes.Finally, we discuss our work in the context of our longer term vision towardsprovably secure distributed systems.
bio: 

Wenchao Zhou is an Assistant Professor in the Department of Computer Science at Georgetown University.His research interests center on the use ofdata-centricandformal techniquestowards ensuringsafe and secure distributed systems. Dr. Zhou received the BSE degree in computer science from Tsinghua University in 2006, and the MSE and PhD degrees in computer science both from the University of Pennsylvania in 2009 and 2012 respectively.
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/337
title: Finding Needles in a Haystack: Secure Provenance in Distributed Systems
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777338
speaker: Nima Asadi
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-08 09:00:00
endDateTime: 2013-05-08 11:00:00
abstract: 

In recent years we have witnessed the growing popularity of social media among Internet users. The integration of social media in a variety of online services, together with the spread of smart phones, has changed the way we gossip, advertise, engage in political debates, and track public health. Social media and the online presence of news organizations have similarly revolutionized how news is created, distributed, and accessed. These changes, in turn, have brought about increasing engagement and contribution of users on the web, thereby making the web more dynamic.  A more dynamic web presents new challenges for web searchan important application of Information Retrieval (IR). A stream of new documents in various forms constantly flows into the web at a very high rate, adding to the old content. In many cases, documents quickly lose their relevance. In these time-sensitive environments, finding relevant content in response to user queries requires a real-time search service. This means that the search service must guarantee immediate availability of new content for search. In addition, the search service must offer a fastyet effectiveranking of documents, which requires an optimized search architecture. These aspects of todays web are at odds with how academic IR researchers have traditionally viewed the web, as a collection of static documents. Moreover, search architectures have received little attention in the IR literature. As a result, academic IR research, for the most part, does not provide a mechanism to efficiently handle a high-velocity stream of documents, nor does it facilitate real- time ranking.  In order to resolve these shortcomings, we need to adapt existing search architectures to the new characteristics of the web. To this end, this dissertation addresses the issues of real-time indexing and explores various search architectures for document ranking. We present an efficient mechanism to index a stream of documents in real-time, thereby enabling immediate availability of content for search. Our index structure works entirely in main memory and provides a mechanism to control inverted list contiguity, thereby enabling faster retrieval. Additionally, we consider document ranking with a machine-learned model, dubbed Learning to Rank (LTR), and introduce a novel multi-stage search architecture that enables fast retrieval and allows for more design flexibility. The stages of our architecture include candidate generation (top-k retrieval), feature extraction, and document re-ranking using tree-based LTR models. We compare this architecture with a traditional monolithic architecture where candidate generation and feature extraction occur simultaneously. As we lay out our multi-stage search architecture, we present optimizations to each stage to facilitate low-latency ranking. These optimizations include a fast approximate algorithm to retrieve top k documents that are potentially most relevant to an input query, document vector organizations for feature extraction, architecture-conscious implementations of tree ensembles for LTR using predication and vectorization, and algorithms to train tree-based LTR models that are fast to evaluate. We also study the efficiency-effectiveness tradeoffs of these techniques, and empirically evaluate our end-to-end architecture on microblog document collections.  As we argue in this work, the techniques from this dissertation can improve the efficiency of search for users without degrading search quality. As web becomes even more dynamic and information continues to be disseminated in real-time, adapting search services to conform to real-time settings will become ever more important. 
Examining Committee:
Committee Chair: Dr. Jimmy Lin
Dean's Representative: Dr. Carol Y. Espy-Wilson
Committee Members:  Dr. Hal Daume III
 Dr. Amol Deshpande
 Dr. Alan Sussman
bio: 
locationRoomNumber: 4185
eventWebsite: https://talks.cs.umd.edu/talks/338
title: PhD Defense: Multi-Stage Search Architectures for Streaming Documents
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777346
speaker: Qi Hu
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-10 10:00:00
endDateTime: 2013-05-10 12:00:00
abstract: 

The $N$-body problem appears in many computational physics simulations. At each time step the computation involves an all-pairs sum whose complexity is quadratic, followed by an update of particle positions. This cost means that it is not practical to solve such dynamic $N$-body problems on large scale. To improve this situation, we use both algorithmic and hardware approaches. Our algorithmic approach is to use the Fast Multipole Method (FMM), which is a divide-and-conquer algorithm that performs a fast $N$-body sum using a spatial decomposition and is often used in a time-stepping or iterative loop, to reduce such quadratic complexity to linear with guaranteed accuracy. Our hardware approach is to use heterogeneous clusters, which comprised of nodes that contain multi-core CPUs tightly coupled with accelerators, such as graphics processors unit (GPU) as our underline parallel processing hardware, on which efficient implementations require highly non-trivial re-designed algorithms.   In this dissertation, we fundamentally reconsider the FMM algorithms on heterogeneous architectures to achieve a significant improvement over recent/previous implementations in literature and to make the algorithm ready for use as a workhorse simulation tool for both time-dependent vortex flow problems and for boundary element methods. Our major contributions include: 
1. Novel FMM data structures using parallel construction algorithms for dynamic problems. 
2. A fast hetegenenous FMM algorithm for both single and multiple computing nodes. 
3. An efficient inter-node communication management using fast parallel data structures. 
4. A scalable FMM algorithm using novel Helmholz decomposition for Vortex Methods (VM).  The proposed algorithms can handle non-uniform distributions with irregular partition shapes to achieve workload balance and their MPI-CUDA implementations are highly tuned up and demonstrate the state of the art performances. 
Examining Committee:
Committee Chair: Dr. Ramani Duraiswami
Co-Chair :  Dr. Nail A. Gumerov
Dean's Representative: Dr. J. Gordon Leishman
 Dr. David Mount
 Dr. Howard Elman
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/346
title: PhD Defense: Scalable Fast Multipole Methods on Heterogeneous Architecture
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777284
speaker: ALex Slivkins
speakerAffiliation: Microsoft Research Silicon Valley  Mountain View
speakerUrl: research.microsoft.com/en-us/people/slivkins/
startDateTime: 2013-05-10 13:00:00
endDateTime: 2013-05-10 14:00:00
abstract: 
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/284
title: to be announced
locationName: 
facilId: 19191919
buildingAbbreviation: 
buildingUrl: 
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777334
speaker: Christoph Koch
speakerAffiliation: EPFL
speakerUrl: http://people.epfl.ch/christoph.koch
startDateTime: 2013-05-13 11:00:00
endDateTime: 2013-05-13 12:00:00
abstract: 



In this talk, I present a system for the automatic synthesis of efficient algorithms specialized for a particular memory hierarchy and a set of storage devices. The developer provides two independent inputs: 1) an algorithm that ignores memory hierarchy and external storage aspects; and 2) a description of the target memory hierarchy, including its topology and parameters. Our system is able to automatically synthesize memory-hierarchy and storage-device-aware algorithms out of those specifications, for tasks such as joins and sorting. The framework is extensible and allows developers to quickly synthesize custom out-of-core algorithms as new storage technologies become available.
bio: 

Christoph Koch is a professor of Computer Science at EPFL, specializing in data management. Until 2010, he was an Associate Professor in the Department of Computer Science at Cornell University. Previously to this, from 2005 to 2007, he was an Associate Professor of Computer Science at Saarland University. Earlier, he obtained his PhD in Artificial Intelligence from TU Vienna and CERN (2001), was a postdoctoral researcher at TU Vienna and the University of Edinburgh (2001-2003), and an assistant professor at TU Vienna (2003-2005). He obtained his Habilitation degree in 2004.He has won Best Paper Awards at PODS 2002, ICALP 2005, and SIGMOD 2011, an Outrageous Ideas and Vision Paper Award at CIDR 2013, a Google Research Award (in 2009), and an ERC Grant (in 2011). He is a PI of the Billion-Euro EUFET Flagship Human Brain Project. He (co-)chaired the program committees of DBPL 2005, WebDB 2008, and ICDE 2011, and was PC vice-chair of ICDE 2008 and ICDE 2009. He has served on the editorial board of ACM Transactions on Internet Technology as well as in numerous program committees.He currently serves as PC co-chair of VLDB 2013 and Editor-in-Chief of PVLDB.
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/334
title: Automatic Synthesis of Out-of-Core Algorithms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777340
speaker: John Alexis Guerra Gomez
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-13 12:00:00
endDateTime: 2013-05-13 14:00:00
abstract: 

Hierarchies are a useful way of representing data. The parent-to-child relationships they define facilitate the analysis of a dataset by breaking it down into its component parts. Representing data as hierarchies can also be used to track changes to a dataset over time or between versions. For example, analysts can use hierarchies to uncover changes in the US Federal Budget in the last twenty years, by grouping accounts by Agencies and Bureaus. Similarly, a company manager can analyze changes to their product sales due to the holiday season by breaking them up by markets and product categories. Exploring differences in such trees could help them understand changes in the data. However, comparing hierarchies is a difficult task, even when comparing two trees with a small number of nodes. To address this, I used information visualization techniques to support data comparison tasks using hierarchies. After evaluating my techniques with domain experts on real world problems, I identified and addressed two main research topics:  First, I tackled the problem of comparing two versions of a tree by using two types of change, while most of the significant work on this topic has focused only on changes in node values or changes in topology. TreeVersity (http://hcil.cs.umd.edu/treeversity) is a comparison tool that allows users to explore changes between two versions of a tree by tracking node value differences, and newly created or removed nodes. Domain experts using TreeVersity were excited to discover differences in the trees, but expressed a desire to explore the evolution of a dataset over time. To that end, they suggested to apply TreeVersity comparison capabilities to non inherently hierarchical datasets.  Thus, I then addressed the problem of exploring changes over time in datasets that can be categorized as trees. TreeVersity2 (http://treeversity.cattlab.umd.edu is a web-based data comparison tool that allows users to explore a tree that change over time and of datasets that are not inherently hierarchical, by categorizing them by its attributes. TreeVersity2 also helps users navigate the sometimes large amounts of differences between versions of a tree using an interactive textual reporting tool.  My research has resulted in two main contributions: First, the introduction of the Bullet, a visualization glyph to represent four characteristics of change (as described in Section [sec:Contributions]) in tree nodes, and the implementation of the Bullet in TreeVersity. Second, the creation of the StemView, a tree visualization technique that represents five characteristics of change in all the nodes of a tree (not just the leaves), and the implementation of the StemView in TreeVersity2. Furthermore, my research resulted in the development of the reporting tool, another feature of TreeVersity2, which helps users navigate outstanding changes in the tree with textual representations and coordinated interactions. Moreover, these developments have been tested in 13 case studies with domain experts on real world comparison problems. The case studies have validated the utility and flexibility of my approaches. Finally, my research opens possibilities for future research on comparing hierarchical structures. 
Examining Committee:
Committee Chair: Dr. Ben Shneiderman
Dean's Representative: Dr. David Lovell
Committee Members:  Dr. Catherine Plaisant
 Dr. Lise Getoor
 Dr. Ben Bederson
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/340
title: PhD Defense: Exploring Differences in Multivariate Datasets Using Hierarchies:  An Interactive Information Visualization Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777341
speaker: Jochen Koenemann
speakerAffiliation: Associate Professor, University of Waterloo 
speakerUrl: http://www.math.uwaterloo.ca/~jochen/
startDateTime: 2013-05-13 13:00:00
endDateTime: 2013-05-13 14:00:00
abstract: The first part of this talk focuses on a network diffusion model that was recently introduced by Goldberg  Liu (SODA'13). Goldberg  Liu's model adapts the earlier linear threshold model of Kempe, Kleinberg  Tardos (KDD'03) in an effort to capture aspects of technology adaptation processes in networks. We present new, improved, yet simple algorithms for the so called Influence Maximization problem in this setting.
A key component of our algorithm is a Langrangean multiplier preserving (LMP) algorithm for the Prize-collecting Node-weighted Steiner Tree problem (PC-NWST). This problem had been studied in prior work by Moss and Rabani (STOC'01  SICOMP'07) who presented a primal-dual O(log |V|) approximate and LMP algorithm, and showed that this is best possible unless NP=P.
We demonstrate that Moss  Rabani's algorithm for PC-NWST is seriously flawed. We then present a new, fundamentally different primal-dual method achieving the same performance guarantee. Our algorithm introduces several novel features to the primal-dual method that may be of independent interest.
Joint work with Laura Sanita and Sina Sadeghian
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/341
title: Network Diffusion & Node-Weighted Steiner Trees
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777345
speaker: Vahid Liaghat
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-14 09:30:00
endDateTime: 2013-05-14 11:00:00
abstract: 

An offline algorithm is one that knows the entire input in advance. An online algorithm, however, processes its input in a serial fashion. In contrast to offline algorithms, an online algorithm works in a local fashion and has to make irrevocable decisions without having the entire input. Online algorithms are often not optimal since their irrevocable decisions may turn out to be inefficient after receiving the rest of the input. For a given online problem, the goal is to design algorithms which are competitive against the offline optimal solutions.  We study the competitive analysis of fundamental problems in the literature such as online matching, online Steiner connectivity, and the k-server problem. Although there are many generic tools for solving an optimization problem in the offline paradigm, much less is known for tackling online problems. A representative example is bipartite matching. Even though bipartite matching is easily computable in the offline setting, solving the problem online is shown to be very challenging. The main focus of our work is to design generic techniques for solving linear optimization problems where the solution space is restricted via a set of linear constraints. A general family of these problems are online packing/covering problems. Our work so far shows that for several seemingly unrelated problems, primal-dual techniques can be successfully applied as a unifying approach for solving these problems. We believe this leads to generic algorithmic frameworks for solving online problems.  In this proposal, we first show the effectiveness of our techniques for both adversarial settings and stochastic settings. In particular, we introduce new techniques for solving two online linear optimization problems, namely, the stochastic generalized assignment problem and the network design problems characterized by proper functions. The former belongs to the family of online packing problems while the later belongs to the family of online covering problems. We next describe the challenges ahead for venturing deeper into either of these major families of problems.
Examining Committee:
Dr. Mohammad Taghi Hajiaghayi -  Chair
Dr. Hector Corrado Bravo -  Deps Representative
Dr. Aravind Srinivasan -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/345
title: PhD Proposal: Online Algorithms with the Uncertainty of Future, A Primal-Dual Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777342
speaker: Panos Chrysanthis
speakerAffiliation: University of Pittsburgh
speakerUrl: http://panos.cs.pitt.edu/
startDateTime: 2013-05-14 11:00:00
endDateTime: 2013-05-14 12:00:00
abstract: TBA
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/342
title: TBA
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777347
speaker: Jeff Stuckman
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-16 13:00:00
endDateTime: 2013-05-16 14:30:00
abstract: 

Security vulnerabilities, or defects in programs that enable their security to be breached, frequently facilitate successful attacks against systems. While software quality metrics to predict defects have been proposed and evaluated in the past, less is known about the performance of security metrics in predicting vulnerabilities and the contexts in which they are effective. In the proposed research, we build a corpus of security vulnerabilities from open-source software, propose security metrics for software artifacts, and empirically evaluate them with respect to current quality and security metrics. 
We build a diverse, representative corpus of vulnerabilities in web applications, storing them in a structured format which links defect information with their relevant source code locations. This corpus will be used to measure the vulnerability prediction performance of traditional metric suites, using processes that avoid confounding variables to which other testing methods are prone. We will then propose, adapt, and evaluate metrics which quantify security-related characteristics such as attack surface, exposure, and privilege, utilizing an established theoretical evaluation method to study these metrics properties.
One product of this research is a substantial corpus of security vulnerabilities, which will become available to the research community to facilitate empirical studies of vulnerabilities and security hardening techniques. Another outcome of this research is unified, comparative data on the vulnerability prediction performance of traditional quality metrics and security-specific metrics, some of which are new or otherwise have not been evaluated. These results are enabled by the application of theoretical and empirical validation methods to attack surface metrics, which have not yet been examined in this way. Finally, this research will produce measurement tools for developers and testers, allowing security metrics to be leveraged for tasks such as estimating the relative security risks of programs or portions of programs, prioritizing code reviews or defense-in-depth measures for specific components, and assessing the security impact of adding a new component
Examining Committee:
Dr. James Purtilo -  Chair
Dr. James Reggia -  Deps Representative
Dr. Michael Hicks -  Committee Member
bio: 
locationRoomNumber: 4103
eventWebsite: https://talks.cs.umd.edu/talks/347
title: PhD Proposal: Developing and Validating Security Vulnerability Indicator Metrics
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777332
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-22 08:30:00
endDateTime: 2013-05-22 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/332
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777333
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-23 08:30:00
endDateTime: 2013-05-23 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/333
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-05 08:57:18
Info: Event is already in the database
id: 777335
speaker: Ashwin Kumar Kayyoor
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-06 10:00:00
endDateTime: 2013-05-06 11:30:00
abstract: 

The rapid increase in the data volumes encountered in many application domains has led to widespread adoption of parallel and distributed data management systems like parallel databases and MapReduce-based frameworks (e.g., Hadoop) in recent years. Use of such parallel or distributed frameworks is expected to accelerate in the coming years, putting further strain on already-scarce resources like compute power, network bandwidth, and energy. For reducing total execution times, there is a trend towards increasing the execution parallelism by spreading out data across a large number of machines. However, this often increases the total resource consumption, and especially energy consumption, significantly. In my dissertation research, I propose to develop data management techniques that minimize resource consumption through workload consolidation.
In the first part of my proposal, I focus on analytical workloads, consisting of read-only queries, being executed across a large number of machines. I argue that, for such workloads, minimizing the query latencies may not be critically important since the queries are often not run in an interactive mode. Instead, I propose that we should aim for reducing the total resource consumption by decreasing the degree of single-query execution parallelism, i.e., by trying to reduce the number of machines involved in the execution of a query (called query span). To that end, I propose workload-driven replica selection and placement algorithms that attempt to minimize the average query span by exploiting the fact that most distributed environments need to use replication for fault tolerance. Preliminary experiments show that judicious data placement and replication can dramatically reduce the average query spans resulting in significant reductions in the resource consumption.
In the second part of my proposal, I propose and study an in-memory MapReduce system optimized for performing complex analytics tasks on input data sizes that fit in a single machine's memory. I argue that systems like Hadoop that are designed to operate across a large number of machines are not optimal in performance for small and medium sized complex analytics tasks because of high startup costs, heavy disk activity, and wasteful checkpointing. I propose developing a prototype runtime called Hone that is both API and binary compatible with standard (distributed) Hadoop. In other words, we can take an existing Hadoop jar and run it, without modification, on a multi-core shared memory machine. This allows us to take existing Hadoop algorithms and find the most suitable runtime environment for execution on datasets of varying sizes.
Finally, I conclude the proposal with the future work I plan to pursue, which is divided into three parts: (a) supporting iterative algorithms in Hone, (b) supporting streaming analytics in Hone, and (c) workload-aware optimization of MapReduce workloads.
Examining Committee:
Dr. Amol Deshpande -  Chair
Dr. Alan Sussman -  Deps Representative
Dr. Jimmy Lin -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/335
title: PhD Proposal: Minimizing Resource Consumption through Consolidation in  Large-Scale Data Analysis Platforms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777337
speaker: Wenchao Zhou
speakerAffiliation: Department of Computer Science at Georgetown University
speakerUrl: http://www.cis.upenn.edu/~wenchaoz/
startDateTime: 2013-05-07 14:00:00
endDateTime: 2013-05-07 15:00:00
abstract: 

Operators of distributed systems often find themselves needing to answer forensic questions, in order to perform a variety of managerial tasks including fault detection, system debugging, accountability enforcement, and attack analysis.In thistalk, we will introduce Secure Network Provenance (SNP), an approach that provides the fundamental functionality required for answering such forensic questions -- the capability to "explain'' the existence (or change) of a certain distributed system state in a potentially adversarial environment.

We modelprovenance maintenance and querying as recursive queries over distributed relations, and propose security extensions toallow operators to reliably query provenanceinformation in adversarial environments. The extensions guarantee thatoperators can eventually detect the presence of compromised nodes thatlie or falsely implicate correct nodes.Finally, we discuss our work in the context of our longer term vision towardsprovably secure distributed systems.
bio: 

Wenchao Zhou is an Assistant Professor in the Department of Computer Science at Georgetown University.His research interests center on the use ofdata-centricandformal techniquestowards ensuringsafe and secure distributed systems. Dr. Zhou received the BSE degree in computer science from Tsinghua University in 2006, and the MSE and PhD degrees in computer science both from the University of Pennsylvania in 2009 and 2012 respectively.
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/337
title: Finding Needles in a Haystack: Secure Provenance in Distributed Systems
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777338
speaker: Nima Asadi
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-08 09:00:00
endDateTime: 2013-05-08 11:00:00
abstract: 

In recent years we have witnessed the growing popularity of social media among Internet users. The integration of social media in a variety of online services, together with the spread of smart phones, has changed the way we gossip, advertise, engage in political debates, and track public health. Social media and the online presence of news organizations have similarly revolutionized how news is created, distributed, and accessed. These changes, in turn, have brought about increasing engagement and contribution of users on the web, thereby making the web more dynamic.  A more dynamic web presents new challenges for web searchan important application of Information Retrieval (IR). A stream of new documents in various forms constantly flows into the web at a very high rate, adding to the old content. In many cases, documents quickly lose their relevance. In these time-sensitive environments, finding relevant content in response to user queries requires a real-time search service. This means that the search service must guarantee immediate availability of new content for search. In addition, the search service must offer a fastyet effectiveranking of documents, which requires an optimized search architecture. These aspects of todays web are at odds with how academic IR researchers have traditionally viewed the web, as a collection of static documents. Moreover, search architectures have received little attention in the IR literature. As a result, academic IR research, for the most part, does not provide a mechanism to efficiently handle a high-velocity stream of documents, nor does it facilitate real- time ranking.  In order to resolve these shortcomings, we need to adapt existing search architectures to the new characteristics of the web. To this end, this dissertation addresses the issues of real-time indexing and explores various search architectures for document ranking. We present an efficient mechanism to index a stream of documents in real-time, thereby enabling immediate availability of content for search. Our index structure works entirely in main memory and provides a mechanism to control inverted list contiguity, thereby enabling faster retrieval. Additionally, we consider document ranking with a machine-learned model, dubbed Learning to Rank (LTR), and introduce a novel multi-stage search architecture that enables fast retrieval and allows for more design flexibility. The stages of our architecture include candidate generation (top-k retrieval), feature extraction, and document re-ranking using tree-based LTR models. We compare this architecture with a traditional monolithic architecture where candidate generation and feature extraction occur simultaneously. As we lay out our multi-stage search architecture, we present optimizations to each stage to facilitate low-latency ranking. These optimizations include a fast approximate algorithm to retrieve top k documents that are potentially most relevant to an input query, document vector organizations for feature extraction, architecture-conscious implementations of tree ensembles for LTR using predication and vectorization, and algorithms to train tree-based LTR models that are fast to evaluate. We also study the efficiency-effectiveness tradeoffs of these techniques, and empirically evaluate our end-to-end architecture on microblog document collections.  As we argue in this work, the techniques from this dissertation can improve the efficiency of search for users without degrading search quality. As web becomes even more dynamic and information continues to be disseminated in real-time, adapting search services to conform to real-time settings will become ever more important. 
Examining Committee:
Committee Chair: Dr. Jimmy Lin
Dean's Representative: Dr. Carol Y. Espy-Wilson
Committee Members:  Dr. Hal Daume III
 Dr. Amol Deshpande
 Dr. Alan Sussman
bio: 
locationRoomNumber: 4185
eventWebsite: https://talks.cs.umd.edu/talks/338
title: PhD Defense: Multi-Stage Search Architectures for Streaming Documents
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777346
speaker: Qi Hu
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-10 10:00:00
endDateTime: 2013-05-10 12:00:00
abstract: 

The $N$-body problem appears in many computational physics simulations. At each time step the computation involves an all-pairs sum whose complexity is quadratic, followed by an update of particle positions. This cost means that it is not practical to solve such dynamic $N$-body problems on large scale. To improve this situation, we use both algorithmic and hardware approaches. Our algorithmic approach is to use the Fast Multipole Method (FMM), which is a divide-and-conquer algorithm that performs a fast $N$-body sum using a spatial decomposition and is often used in a time-stepping or iterative loop, to reduce such quadratic complexity to linear with guaranteed accuracy. Our hardware approach is to use heterogeneous clusters, which comprised of nodes that contain multi-core CPUs tightly coupled with accelerators, such as graphics processors unit (GPU) as our underline parallel processing hardware, on which efficient implementations require highly non-trivial re-designed algorithms.   In this dissertation, we fundamentally reconsider the FMM algorithms on heterogeneous architectures to achieve a significant improvement over recent/previous implementations in literature and to make the algorithm ready for use as a workhorse simulation tool for both time-dependent vortex flow problems and for boundary element methods. Our major contributions include: 
1. Novel FMM data structures using parallel construction algorithms for dynamic problems. 
2. A fast hetegenenous FMM algorithm for both single and multiple computing nodes. 
3. An efficient inter-node communication management using fast parallel data structures. 
4. A scalable FMM algorithm using novel Helmholz decomposition for Vortex Methods (VM).  The proposed algorithms can handle non-uniform distributions with irregular partition shapes to achieve workload balance and their MPI-CUDA implementations are highly tuned up and demonstrate the state of the art performances. 
Examining Committee:
Committee Chair: Dr. Ramani Duraiswami
Co-Chair :  Dr. Nail A. Gumerov
Dean's Representative: Dr. J. Gordon Leishman
 Dr. David Mount
 Dr. Howard Elman
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/346
title: PhD Defense: Scalable Fast Multipole Methods on Heterogeneous Architecture
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777284
speaker: ALex Slivkins
speakerAffiliation: Microsoft Research Silicon Valley  Mountain View
speakerUrl: research.microsoft.com/en-us/people/slivkins/
startDateTime: 2013-05-10 13:00:00
endDateTime: 2013-05-10 14:00:00
abstract: 
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/284
title: to be announced
locationName: 
facilId: 19191919
buildingAbbreviation: 
buildingUrl: 
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777334
speaker: Christoph Koch
speakerAffiliation: EPFL
speakerUrl: http://people.epfl.ch/christoph.koch
startDateTime: 2013-05-13 11:00:00
endDateTime: 2013-05-13 12:00:00
abstract: 



In this talk, I present a system for the automatic synthesis of efficient algorithms specialized for a particular memory hierarchy and a set of storage devices. The developer provides two independent inputs: 1) an algorithm that ignores memory hierarchy and external storage aspects; and 2) a description of the target memory hierarchy, including its topology and parameters. Our system is able to automatically synthesize memory-hierarchy and storage-device-aware algorithms out of those specifications, for tasks such as joins and sorting. The framework is extensible and allows developers to quickly synthesize custom out-of-core algorithms as new storage technologies become available.
bio: 

Christoph Koch is a professor of Computer Science at EPFL, specializing in data management. Until 2010, he was an Associate Professor in the Department of Computer Science at Cornell University. Previously to this, from 2005 to 2007, he was an Associate Professor of Computer Science at Saarland University. Earlier, he obtained his PhD in Artificial Intelligence from TU Vienna and CERN (2001), was a postdoctoral researcher at TU Vienna and the University of Edinburgh (2001-2003), and an assistant professor at TU Vienna (2003-2005). He obtained his Habilitation degree in 2004.He has won Best Paper Awards at PODS 2002, ICALP 2005, and SIGMOD 2011, an Outrageous Ideas and Vision Paper Award at CIDR 2013, a Google Research Award (in 2009), and an ERC Grant (in 2011). He is a PI of the Billion-Euro EUFET Flagship Human Brain Project. He (co-)chaired the program committees of DBPL 2005, WebDB 2008, and ICDE 2011, and was PC vice-chair of ICDE 2008 and ICDE 2009. He has served on the editorial board of ACM Transactions on Internet Technology as well as in numerous program committees.He currently serves as PC co-chair of VLDB 2013 and Editor-in-Chief of PVLDB.
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/334
title: Automatic Synthesis of Out-of-Core Algorithms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777340
speaker: John Alexis Guerra Gomez
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-13 12:00:00
endDateTime: 2013-05-13 14:00:00
abstract: 

Hierarchies are a useful way of representing data. The parent-to-child relationships they define facilitate the analysis of a dataset by breaking it down into its component parts. Representing data as hierarchies can also be used to track changes to a dataset over time or between versions. For example, analysts can use hierarchies to uncover changes in the US Federal Budget in the last twenty years, by grouping accounts by Agencies and Bureaus. Similarly, a company manager can analyze changes to their product sales due to the holiday season by breaking them up by markets and product categories. Exploring differences in such trees could help them understand changes in the data. However, comparing hierarchies is a difficult task, even when comparing two trees with a small number of nodes. To address this, I used information visualization techniques to support data comparison tasks using hierarchies. After evaluating my techniques with domain experts on real world problems, I identified and addressed two main research topics:  First, I tackled the problem of comparing two versions of a tree by using two types of change, while most of the significant work on this topic has focused only on changes in node values or changes in topology. TreeVersity (http://hcil.cs.umd.edu/treeversity) is a comparison tool that allows users to explore changes between two versions of a tree by tracking node value differences, and newly created or removed nodes. Domain experts using TreeVersity were excited to discover differences in the trees, but expressed a desire to explore the evolution of a dataset over time. To that end, they suggested to apply TreeVersity comparison capabilities to non inherently hierarchical datasets.  Thus, I then addressed the problem of exploring changes over time in datasets that can be categorized as trees. TreeVersity2 (http://treeversity.cattlab.umd.edu is a web-based data comparison tool that allows users to explore a tree that change over time and of datasets that are not inherently hierarchical, by categorizing them by its attributes. TreeVersity2 also helps users navigate the sometimes large amounts of differences between versions of a tree using an interactive textual reporting tool.  My research has resulted in two main contributions: First, the introduction of the Bullet, a visualization glyph to represent four characteristics of change (as described in Section [sec:Contributions]) in tree nodes, and the implementation of the Bullet in TreeVersity. Second, the creation of the StemView, a tree visualization technique that represents five characteristics of change in all the nodes of a tree (not just the leaves), and the implementation of the StemView in TreeVersity2. Furthermore, my research resulted in the development of the reporting tool, another feature of TreeVersity2, which helps users navigate outstanding changes in the tree with textual representations and coordinated interactions. Moreover, these developments have been tested in 13 case studies with domain experts on real world comparison problems. The case studies have validated the utility and flexibility of my approaches. Finally, my research opens possibilities for future research on comparing hierarchical structures. 
Examining Committee:
Committee Chair: Dr. Ben Shneiderman
Dean's Representative: Dr. David Lovell
Committee Members:  Dr. Catherine Plaisant
 Dr. Lise Getoor
 Dr. Ben Bederson
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/340
title: PhD Defense: Exploring Differences in Multivariate Datasets Using Hierarchies:  An Interactive Information Visualization Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777341
speaker: Jochen Koenemann
speakerAffiliation: Associate Professor, University of Waterloo 
speakerUrl: http://www.math.uwaterloo.ca/~jochen/
startDateTime: 2013-05-13 13:00:00
endDateTime: 2013-05-13 14:00:00
abstract: The first part of this talk focuses on a network diffusion model that was recently introduced by Goldberg  Liu (SODA'13). Goldberg  Liu's model adapts the earlier linear threshold model of Kempe, Kleinberg  Tardos (KDD'03) in an effort to capture aspects of technology adaptation processes in networks. We present new, improved, yet simple algorithms for the so called Influence Maximization problem in this setting.
A key component of our algorithm is a Langrangean multiplier preserving (LMP) algorithm for the Prize-collecting Node-weighted Steiner Tree problem (PC-NWST). This problem had been studied in prior work by Moss and Rabani (STOC'01  SICOMP'07) who presented a primal-dual O(log |V|) approximate and LMP algorithm, and showed that this is best possible unless NP=P.
We demonstrate that Moss  Rabani's algorithm for PC-NWST is seriously flawed. We then present a new, fundamentally different primal-dual method achieving the same performance guarantee. Our algorithm introduces several novel features to the primal-dual method that may be of independent interest.
Joint work with Laura Sanita and Sina Sadeghian
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/341
title: Network Diffusion & Node-Weighted Steiner Trees
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777345
speaker: Vahid Liaghat
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-14 09:30:00
endDateTime: 2013-05-14 11:00:00
abstract: 

An offline algorithm is one that knows the entire input in advance. An online algorithm, however, processes its input in a serial fashion. In contrast to offline algorithms, an online algorithm works in a local fashion and has to make irrevocable decisions without having the entire input. Online algorithms are often not optimal since their irrevocable decisions may turn out to be inefficient after receiving the rest of the input. For a given online problem, the goal is to design algorithms which are competitive against the offline optimal solutions.  We study the competitive analysis of fundamental problems in the literature such as online matching, online Steiner connectivity, and the k-server problem. Although there are many generic tools for solving an optimization problem in the offline paradigm, much less is known for tackling online problems. A representative example is bipartite matching. Even though bipartite matching is easily computable in the offline setting, solving the problem online is shown to be very challenging. The main focus of our work is to design generic techniques for solving linear optimization problems where the solution space is restricted via a set of linear constraints. A general family of these problems are online packing/covering problems. Our work so far shows that for several seemingly unrelated problems, primal-dual techniques can be successfully applied as a unifying approach for solving these problems. We believe this leads to generic algorithmic frameworks for solving online problems.  In this proposal, we first show the effectiveness of our techniques for both adversarial settings and stochastic settings. In particular, we introduce new techniques for solving two online linear optimization problems, namely, the stochastic generalized assignment problem and the network design problems characterized by proper functions. The former belongs to the family of online packing problems while the later belongs to the family of online covering problems. We next describe the challenges ahead for venturing deeper into either of these major families of problems.
Examining Committee:
Dr. Mohammad Taghi Hajiaghayi -  Chair
Dr. Hector Corrado Bravo -  Deps Representative
Dr. Aravind Srinivasan -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/345
title: PhD Proposal: Online Algorithms with the Uncertainty of Future, A Primal-Dual Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777342
speaker: Panos Chrysanthis
speakerAffiliation: University of Pittsburgh
speakerUrl: http://panos.cs.pitt.edu/
startDateTime: 2013-05-14 11:00:00
endDateTime: 2013-05-14 12:00:00
abstract: TBA
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/342
title: TBA
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777347
speaker: Jeff Stuckman
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-16 13:00:00
endDateTime: 2013-05-16 14:30:00
abstract: 

Security vulnerabilities, or defects in programs that enable their security to be breached, frequently facilitate successful attacks against systems. While software quality metrics to predict defects have been proposed and evaluated in the past, less is known about the performance of security metrics in predicting vulnerabilities and the contexts in which they are effective. In the proposed research, we build a corpus of security vulnerabilities from open-source software, propose security metrics for software artifacts, and empirically evaluate them with respect to current quality and security metrics. 
We build a diverse, representative corpus of vulnerabilities in web applications, storing them in a structured format which links defect information with their relevant source code locations. This corpus will be used to measure the vulnerability prediction performance of traditional metric suites, using processes that avoid confounding variables to which other testing methods are prone. We will then propose, adapt, and evaluate metrics which quantify security-related characteristics such as attack surface, exposure, and privilege, utilizing an established theoretical evaluation method to study these metrics properties.
One product of this research is a substantial corpus of security vulnerabilities, which will become available to the research community to facilitate empirical studies of vulnerabilities and security hardening techniques. Another outcome of this research is unified, comparative data on the vulnerability prediction performance of traditional quality metrics and security-specific metrics, some of which are new or otherwise have not been evaluated. These results are enabled by the application of theoretical and empirical validation methods to attack surface metrics, which have not yet been examined in this way. Finally, this research will produce measurement tools for developers and testers, allowing security metrics to be leveraged for tasks such as estimating the relative security risks of programs or portions of programs, prioritizing code reviews or defense-in-depth measures for specific components, and assessing the security impact of adding a new component
Examining Committee:
Dr. James Purtilo -  Chair
Dr. James Reggia -  Deps Representative
Dr. Michael Hicks -  Committee Member
bio: 
locationRoomNumber: 4103
eventWebsite: https://talks.cs.umd.edu/talks/347
title: PhD Proposal: Developing and Validating Security Vulnerability Indicator Metrics
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777348
speaker: Pankaj Jalote
speakerAffiliation: IIIT-Delhi
speakerUrl: http://www.iiitd.edu.in/~jalote/
startDateTime: 2013-05-17 11:00:00
endDateTime: 2013-05-17 12:00:00
abstract: Challenges in Engineering Education in Indiaand Opportunities at IIIT-Delhi
Pankaj Jalote
Professor and Director
Indraprastha Institute of Information Technology (IIIT) Delhi
New Delhi
The challenges faced by countries like India in engineering education tend to be different from those in developed countries. This talk will discuss the challenge of growth and scale, quality and faculty, and the RD ecosystem. Within the RD ecosystem challenge, it will discuss the role of research and research universities, issue of PhD production, the importance of relevant industry, and appropriateness of research agenda.
The second part of the talk will discuss the background of IIIT-Delhi, its current state, and the exciting opportunity it offers to young researchers who want to make a mark in academics from India.
bio: 
locationRoomNumber: 2120
eventWebsite: https://talks.cs.umd.edu/talks/348
title: Challenges in Engineering Education in India and Opportunities at IIIT-Delhi
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-06 08:57:18
id: 777349
speaker: Udayan Khurana
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-17 15:00:00
endDateTime: 2013-05-17 16:30:00
abstract: 

Over the last decade, we have witnessed an increasing availability of large volumes of temporally annotated data forinformation networks such as social networks, financial transaction networks, transportation networks and many others.This has fueled an interest in temporal or dynamic analysis, which has the potential to provide crucial insights intovarious temporal or evolutionary aspects of a network.We address the problem of managing historical data for such large evolving information networkswith the goal to enable temporal and evolutionary queries and analytics.
In the first part of this proposal, we present the design and architecture of a distributed graphdatabase system. It stores the entire history of a network and provides support forefficient retrieval of multiple graphs from arbitrary time points in the past, in addition tomaintaining the current state for ongoing updates.Our system exposes a general programmatic API to process and analyze the retrieved snapshots.We introduceDeltaGraph, anovel, extensible, highly tunable, and distributed hierarchical index structure that enables compact recording of thehistorical information. DeltaGraph supports efficient retrieval of historical graph snapshots for single-siteor parallel processing.Along with the original graph data, DeltaGraph can also maintain and indexauxiliaryinformation using itsextensibilityframework; this functionality can be used to extend the structure to efficiently execute queries likesubgraph patternmatchingover historical data.We develop analytical models for both the storage space needed and the snapshot retrieval times to aidin choosing the right parameters for a specific scenario. In addition, we present strategies for materializingportions of the historical graph state in memory to further speed up the retrieval process.We also present an in-memory graph data structure calledGraphPoolthat can maintain hundreds ofhistorical graph instances in main memory in a non-redundant manner. 
In the second part of the proposal, we focus on diversified needs of a historical graph data management system. First, we proposemodifications to DeltaGraph to enable efficient retrieval of subgraphs forego-centricandneighborhood-centricanalysis queries. Second, we proposestudying and dealing with runtime challenges of a dynamic historical graph database such as handling updates, optimizing multiple queries together andadapting to changing query-loads. Third, we focus our attention on efficiently executing specific queries such asevolving shortest pathsordynamic reachabilityusing DeltaGraph's extensibility framework. We also look at understanding and hence optimizing historical networkanalysis queries expressed in a declarative syntax. Finally, we explore the applicability of some of these techniques to large scale dynamic dataother than graphs, particularly, scientific array databases and timeseries data.
Examining Committee:
Dr. Amol Deshpande       - Chair
Dr. Ben Shneiderman      -  Deps Representative
Dr. Nick Roussopoulos     -  Committee Member
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/349
title: PhD Proposal: Historical Graph Data Management
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-06 08:57:18
id: 777332
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-22 08:30:00
endDateTime: 2013-05-22 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/332
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777333
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-23 08:30:00
endDateTime: 2013-05-23 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/333
title: Human-Computer Interaction Lab's 30th Annual Symposium
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-06 08:57:18
Info: Event is already in the database
id: 777337
speaker: Wenchao Zhou
speakerAffiliation: Department of Computer Science at Georgetown University
speakerUrl: http://www.cis.upenn.edu/~wenchaoz/
startDateTime: 2013-05-07 14:00:00
endDateTime: 2013-05-07 15:00:00
abstract: 

Operators of distributed systems often find themselves needing to answer forensic questions, in order to perform a variety of managerial tasks including fault detection, system debugging, accountability enforcement, and attack analysis.In thistalk, we will introduce Secure Network Provenance (SNP), an approach that provides the fundamental functionality required for answering such forensic questions -- the capability to "explain'' the existence (or change) of a certain distributed system state in a potentially adversarial environment.

We modelprovenance maintenance and querying as recursive queries over distributed relations, and propose security extensions toallow operators to reliably query provenanceinformation in adversarial environments. The extensions guarantee thatoperators can eventually detect the presence of compromised nodes thatlie or falsely implicate correct nodes.Finally, we discuss our work in the context of our longer term vision towardsprovably secure distributed systems.
bio: 

Wenchao Zhou is an Assistant Professor in the Department of Computer Science at Georgetown University.His research interests center on the use ofdata-centricandformal techniquestowards ensuringsafe and secure distributed systems. Dr. Zhou received the BSE degree in computer science from Tsinghua University in 2006, and the MSE and PhD degrees in computer science both from the University of Pennsylvania in 2009 and 2012 respectively.
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/337
title: Finding Needles in a Haystack: Secure Provenance in Distributed Systems
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777338
speaker: Nima Asadi
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-08 09:00:00
endDateTime: 2013-05-08 11:00:00
abstract: 

In recent years we have witnessed the growing popularity of social media among Internet users. The integration of social media in a variety of online services, together with the spread of smart phones, has changed the way we gossip, advertise, engage in political debates, and track public health. Social media and the online presence of news organizations have similarly revolutionized how news is created, distributed, and accessed. These changes, in turn, have brought about increasing engagement and contribution of users on the web, thereby making the web more dynamic.  A more dynamic web presents new challenges for web searchan important application of Information Retrieval (IR). A stream of new documents in various forms constantly flows into the web at a very high rate, adding to the old content. In many cases, documents quickly lose their relevance. In these time-sensitive environments, finding relevant content in response to user queries requires a real-time search service. This means that the search service must guarantee immediate availability of new content for search. In addition, the search service must offer a fastyet effectiveranking of documents, which requires an optimized search architecture. These aspects of todays web are at odds with how academic IR researchers have traditionally viewed the web, as a collection of static documents. Moreover, search architectures have received little attention in the IR literature. As a result, academic IR research, for the most part, does not provide a mechanism to efficiently handle a high-velocity stream of documents, nor does it facilitate real- time ranking.  In order to resolve these shortcomings, we need to adapt existing search architectures to the new characteristics of the web. To this end, this dissertation addresses the issues of real-time indexing and explores various search architectures for document ranking. We present an efficient mechanism to index a stream of documents in real-time, thereby enabling immediate availability of content for search. Our index structure works entirely in main memory and provides a mechanism to control inverted list contiguity, thereby enabling faster retrieval. Additionally, we consider document ranking with a machine-learned model, dubbed Learning to Rank (LTR), and introduce a novel multi-stage search architecture that enables fast retrieval and allows for more design flexibility. The stages of our architecture include candidate generation (top-k retrieval), feature extraction, and document re-ranking using tree-based LTR models. We compare this architecture with a traditional monolithic architecture where candidate generation and feature extraction occur simultaneously. As we lay out our multi-stage search architecture, we present optimizations to each stage to facilitate low-latency ranking. These optimizations include a fast approximate algorithm to retrieve top k documents that are potentially most relevant to an input query, document vector organizations for feature extraction, architecture-conscious implementations of tree ensembles for LTR using predication and vectorization, and algorithms to train tree-based LTR models that are fast to evaluate. We also study the efficiency-effectiveness tradeoffs of these techniques, and empirically evaluate our end-to-end architecture on microblog document collections.  As we argue in this work, the techniques from this dissertation can improve the efficiency of search for users without degrading search quality. As web becomes even more dynamic and information continues to be disseminated in real-time, adapting search services to conform to real-time settings will become ever more important. 
Examining Committee:
Committee Chair: Dr. Jimmy Lin
Dean's Representative: Dr. Carol Y. Espy-Wilson
Committee Members:  Dr. Hal Daume III
 Dr. Amol Deshpande
 Dr. Alan Sussman
bio: 
locationRoomNumber: 4185
eventWebsite: https://talks.cs.umd.edu/talks/338
title: PhD Defense: Multi-Stage Search Architectures for Streaming Documents
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777346
speaker: Qi Hu
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-10 10:00:00
endDateTime: 2013-05-10 12:00:00
abstract: 

The $N$-body problem appears in many computational physics simulations. At each time step the computation involves an all-pairs sum whose complexity is quadratic, followed by an update of particle positions. This cost means that it is not practical to solve such dynamic $N$-body problems on large scale. To improve this situation, we use both algorithmic and hardware approaches. Our algorithmic approach is to use the Fast Multipole Method (FMM), which is a divide-and-conquer algorithm that performs a fast $N$-body sum using a spatial decomposition and is often used in a time-stepping or iterative loop, to reduce such quadratic complexity to linear with guaranteed accuracy. Our hardware approach is to use heterogeneous clusters, which comprised of nodes that contain multi-core CPUs tightly coupled with accelerators, such as graphics processors unit (GPU) as our underline parallel processing hardware, on which efficient implementations require highly non-trivial re-designed algorithms.   In this dissertation, we fundamentally reconsider the FMM algorithms on heterogeneous architectures to achieve a significant improvement over recent/previous implementations in literature and to make the algorithm ready for use as a workhorse simulation tool for both time-dependent vortex flow problems and for boundary element methods. Our major contributions include: 
1. Novel FMM data structures using parallel construction algorithms for dynamic problems. 
2. A fast hetegenenous FMM algorithm for both single and multiple computing nodes. 
3. An efficient inter-node communication management using fast parallel data structures. 
4. A scalable FMM algorithm using novel Helmholz decomposition for Vortex Methods (VM).  The proposed algorithms can handle non-uniform distributions with irregular partition shapes to achieve workload balance and their MPI-CUDA implementations are highly tuned up and demonstrate the state of the art performances. 
Examining Committee:
Committee Chair: Dr. Ramani Duraiswami
Co-Chair :  Dr. Nail A. Gumerov
Dean's Representative: Dr. J. Gordon Leishman
 Dr. David Mount
 Dr. Howard Elman
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/346
title: PhD Defense: Scalable Fast Multipole Methods on Heterogeneous Architecture
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777284
speaker: ALex Slivkins
speakerAffiliation: Microsoft Research Silicon Valley  Mountain View
speakerUrl: research.microsoft.com/en-us/people/slivkins/
startDateTime: 2013-05-10 13:00:00
endDateTime: 2013-05-10 14:00:00
abstract: It is commonly assumed that individuals tend to be more similar to their friends than to strangers. Thus, we can view an observed social network as a noisy signal about the latent underlying "social space": the way in which individuals are (dis)similar. This naturally raises the inverse question: given a social network, how accurately can we reconstruct the social space?
We begin to address this problem formally. We assume that each category (e.g., geography, profession, hobbies) is characterized by a latent metric capturing (dis)similarities in this category, and gives rise to a separate social network: a random graph parameterized by this metric. The algorithm only observes the unlabeled union of these graphs, and reconstructs each metric with provably low distortion.
Joint work with Ittai Abraham (MSR-SV), Shiri Chechik (MSR-SV) and David Kempe (USC). Appeared in SODA 2013.
bio: Alex Slivkins is a researcher at Microsoft Research Silicon Valley since 2007. He joined MSR-SV after a one-year postdoc at Brown University, where he was working with Eli Upfal. He received his Ph.D. in Computer Science from Cornell University, advised by Jon Kleinberg, after completing undergraduate studies at Caltech. His research interests lie in the design and analysis of algorithms, for domains such as machine learning, algorithmic economics, and social and technological networks. He has authored over 25 papers in top computer science conferences in several areas: theoryalgorithms (FOCS,STOC,SODA,PODC), machine learning (COLT,ICML,NIPS), algorithmic economics (ACM-EC), and networking (SIGCOMM, INFOCOM). His work was recognized by ACM EC 2010 best paper award, and ACM PODC 2005 best student paper award.
locationRoomNumber: 
eventWebsite: https://talks.cs.umd.edu/talks/284
title: Reconstructing Latent Similarities in a Multiplex Social Network 
locationName: 
facilId: 19191919
buildingAbbreviation: 
buildingUrl: 
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777334
speaker: Christoph Koch
speakerAffiliation: EPFL
speakerUrl: http://people.epfl.ch/christoph.koch
startDateTime: 2013-05-13 11:00:00
endDateTime: 2013-05-13 12:00:00
abstract: 



In this talk, I present a system for the automatic synthesis of efficient algorithms specialized for a particular memory hierarchy and a set of storage devices. The developer provides two independent inputs: 1) an algorithm that ignores memory hierarchy and external storage aspects; and 2) a description of the target memory hierarchy, including its topology and parameters. Our system is able to automatically synthesize memory-hierarchy and storage-device-aware algorithms out of those specifications, for tasks such as joins and sorting. The framework is extensible and allows developers to quickly synthesize custom out-of-core algorithms as new storage technologies become available.
bio: 

Christoph Koch is a professor of Computer Science at EPFL, specializing in data management. Until 2010, he was an Associate Professor in the Department of Computer Science at Cornell University. Previously to this, from 2005 to 2007, he was an Associate Professor of Computer Science at Saarland University. Earlier, he obtained his PhD in Artificial Intelligence from TU Vienna and CERN (2001), was a postdoctoral researcher at TU Vienna and the University of Edinburgh (2001-2003), and an assistant professor at TU Vienna (2003-2005). He obtained his Habilitation degree in 2004.He has won Best Paper Awards at PODS 2002, ICALP 2005, and SIGMOD 2011, an Outrageous Ideas and Vision Paper Award at CIDR 2013, a Google Research Award (in 2009), and an ERC Grant (in 2011). He is a PI of the Billion-Euro EUFET Flagship Human Brain Project. He (co-)chaired the program committees of DBPL 2005, WebDB 2008, and ICDE 2011, and was PC vice-chair of ICDE 2008 and ICDE 2009. He has served on the editorial board of ACM Transactions on Internet Technology as well as in numerous program committees.He currently serves as PC co-chair of VLDB 2013 and Editor-in-Chief of PVLDB.
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/334
title: Automatic Synthesis of Out-of-Core Algorithms
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777340
speaker: John Alexis Guerra Gomez
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-13 12:00:00
endDateTime: 2013-05-13 14:00:00
abstract: 

Hierarchies are a useful way of representing data. The parent-to-child relationships they define facilitate the analysis of a dataset by breaking it down into its component parts. Representing data as hierarchies can also be used to track changes to a dataset over time or between versions. For example, analysts can use hierarchies to uncover changes in the US Federal Budget in the last twenty years, by grouping accounts by Agencies and Bureaus. Similarly, a company manager can analyze changes to their product sales due to the holiday season by breaking them up by markets and product categories. Exploring differences in such trees could help them understand changes in the data. However, comparing hierarchies is a difficult task, even when comparing two trees with a small number of nodes. To address this, I used information visualization techniques to support data comparison tasks using hierarchies. After evaluating my techniques with domain experts on real world problems, I identified and addressed two main research topics:  First, I tackled the problem of comparing two versions of a tree by using two types of change, while most of the significant work on this topic has focused only on changes in node values or changes in topology. TreeVersity (http://hcil.cs.umd.edu/treeversity) is a comparison tool that allows users to explore changes between two versions of a tree by tracking node value differences, and newly created or removed nodes. Domain experts using TreeVersity were excited to discover differences in the trees, but expressed a desire to explore the evolution of a dataset over time. To that end, they suggested to apply TreeVersity comparison capabilities to non inherently hierarchical datasets.  Thus, I then addressed the problem of exploring changes over time in datasets that can be categorized as trees. TreeVersity2 (http://treeversity.cattlab.umd.edu is a web-based data comparison tool that allows users to explore a tree that change over time and of datasets that are not inherently hierarchical, by categorizing them by its attributes. TreeVersity2 also helps users navigate the sometimes large amounts of differences between versions of a tree using an interactive textual reporting tool.  My research has resulted in two main contributions: First, the introduction of the Bullet, a visualization glyph to represent four characteristics of change (as described in Section [sec:Contributions]) in tree nodes, and the implementation of the Bullet in TreeVersity. Second, the creation of the StemView, a tree visualization technique that represents five characteristics of change in all the nodes of a tree (not just the leaves), and the implementation of the StemView in TreeVersity2. Furthermore, my research resulted in the development of the reporting tool, another feature of TreeVersity2, which helps users navigate outstanding changes in the tree with textual representations and coordinated interactions. Moreover, these developments have been tested in 13 case studies with domain experts on real world comparison problems. The case studies have validated the utility and flexibility of my approaches. Finally, my research opens possibilities for future research on comparing hierarchical structures. 
Examining Committee:
Committee Chair: Dr. Ben Shneiderman
Dean's Representative: Dr. David Lovell
Committee Members:  Dr. Catherine Plaisant
 Dr. Lise Getoor
 Dr. Ben Bederson
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/340
title: PhD Defense: Exploring Differences in Multivariate Datasets Using Hierarchies:  An Interactive Information Visualization Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777341
speaker: Jochen Koenemann
speakerAffiliation: Associate Professor, University of Waterloo 
speakerUrl: http://www.math.uwaterloo.ca/~jochen/
startDateTime: 2013-05-13 13:00:00
endDateTime: 2013-05-13 14:00:00
abstract: The first part of this talk focuses on a network diffusion model that was recently introduced by Goldberg  Liu (SODA'13). Goldberg  Liu's model adapts the earlier linear threshold model of Kempe, Kleinberg  Tardos (KDD'03) in an effort to capture aspects of technology adaptation processes in networks. We present new, improved, yet simple algorithms for the so called Influence Maximization problem in this setting.
A key component of our algorithm is a Langrangean multiplier preserving (LMP) algorithm for the Prize-collecting Node-weighted Steiner Tree problem (PC-NWST). This problem had been studied in prior work by Moss and Rabani (STOC'01  SICOMP'07) who presented a primal-dual O(log |V|) approximate and LMP algorithm, and showed that this is best possible unless NP=P.
We demonstrate that Moss  Rabani's algorithm for PC-NWST is seriously flawed. We then present a new, fundamentally different primal-dual method achieving the same performance guarantee. Our algorithm introduces several novel features to the primal-dual method that may be of independent interest.
Joint work with Laura Sanita and Sina Sadeghian
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/341
title: Network Diffusion & Node-Weighted Steiner Trees
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777345
speaker: Vahid Liaghat
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-14 09:30:00
endDateTime: 2013-05-14 11:00:00
abstract: 

An offline algorithm is one that knows the entire input in advance. An online algorithm, however, processes its input in a serial fashion. In contrast to offline algorithms, an online algorithm works in a local fashion and has to make irrevocable decisions without having the entire input. Online algorithms are often not optimal since their irrevocable decisions may turn out to be inefficient after receiving the rest of the input. For a given online problem, the goal is to design algorithms which are competitive against the offline optimal solutions.  We study the competitive analysis of fundamental problems in the literature such as online matching, online Steiner connectivity, and the k-server problem. Although there are many generic tools for solving an optimization problem in the offline paradigm, much less is known for tackling online problems. A representative example is bipartite matching. Even though bipartite matching is easily computable in the offline setting, solving the problem online is shown to be very challenging. The main focus of our work is to design generic techniques for solving linear optimization problems where the solution space is restricted via a set of linear constraints. A general family of these problems are online packing/covering problems. Our work so far shows that for several seemingly unrelated problems, primal-dual techniques can be successfully applied as a unifying approach for solving these problems. We believe this leads to generic algorithmic frameworks for solving online problems.  In this proposal, we first show the effectiveness of our techniques for both adversarial settings and stochastic settings. In particular, we introduce new techniques for solving two online linear optimization problems, namely, the stochastic generalized assignment problem and the network design problems characterized by proper functions. The former belongs to the family of online packing problems while the later belongs to the family of online covering problems. We next describe the challenges ahead for venturing deeper into either of these major families of problems.
Examining Committee:
Dr. Mohammad Taghi Hajiaghayi -  Chair
Dr. Hector Corrado Bravo -  Deps Representative
Dr. Aravind Srinivasan -  Committee Member
bio: 
locationRoomNumber: 3258
eventWebsite: https://talks.cs.umd.edu/talks/345
title: PhD Proposal: Online Algorithms with the Uncertainty of Future, A Primal-Dual Approach
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777342
speaker: Panos Chrysanthis
speakerAffiliation: University of Pittsburgh
speakerUrl: http://panos.cs.pitt.edu/
startDateTime: 2013-05-14 11:00:00
endDateTime: 2013-05-14 12:00:00
abstract: For the past few years, our group has been working on problems relatedto Big Data through several projects. After briefly discussing theseprojects, the rest of this talk will present DILoS, which focuses onthree of the five Big Data's Vs, that is, volume, velocity andvariability.Today, the ubiquity of sensing devices as well as of mobile and webapplications continuously generates a huge amount of data which takesthe form of streams. These data streams are typically high-volume,often high-velocity (speed) and high-variability (bursty). It is notonly the rates, but also the value distribution of data streams thatusually fluctuates in an unpredictable fashion. In order to meet thenear-real-time requirements of the monitoring applications and of theemerging ``Big Data'' applications, data streams need to becontinuously processed and analyzed. Such processing happens inside Data stream management systems (DSMSs), which efficiently support continuous queries (CQs).CQs inherently have different levels of criticality and hencedifferent levels of expected quality of service (QoS) and quality ofdata (QoD). In order to provide different quality guarantees, i.e.,service level agreements (SLAs), to different client streamapplications, we developed DILoS, a novel framework that exploits thesynergy between scheduling and load shedding in DSMS. In overloadsituations, DILoS enforces worst-case response times for all CQs whileproviding prioritized QoD, i.e., minimize data loss for query classesaccording to their priorities. We further propose ALoMa, a newadaptive load manager scheme that enables the realization of the DILoSframework. ALoMa is a general, practical DSMS load shedder thatoutperforms the state-of-the-art in deciding when the DSMS is overloadand how much load needs to be shed. We implemented DILoS in our realDSMS prototype system (AQSIOS) and evaluate its performance for avariety of real and synthetic workloads. Our experiments show thatour framework (1) allows the scheduler and load shedder toconsistently honor CQs' priorities and (2) maximizes the utilizationof the system processing capacity to reduce load shedding.
bio: Panos K. Chrysanthis is a Professor of Computer Science and thefounding director of the Advanced Data Management TechnologiesLaboratory (ADMT Lab) [http://db.cs.pitt.edu] at the University ofPittsburgh. His lab has a broad focus on user-centric data managementfor scalable network-centric and collaborative applications and hasfostered interdisciplinary collaborations between computer science,medicine and astronomy, both within and outside the University ofPittsburgh -- he is an Adjunct Professor at the Carnegie MellonUniversity and at the University of Cyprus, Cyprus. In 1995, hereceived one of the first NSF CAREER Awards for his pioneer work onmobile data management and in 2010, he was recognized as aDistinguished Scientist by ACM. In 2007, he was also elevated to thelevel of a Senior Member of IEEE.DILoS was developed in collaboration with Thao N. Pham (as part of herPhD thesis) and Alexandros Labrinidis who is the co-director of the ADMTlab. This work has been funded in part by two NSF Awards and a gift from EMC/Greenplum.
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/342
title: Handling the Three Vs of Big Data with DILoS 
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777347
speaker: Jeff Stuckman
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-16 13:00:00
endDateTime: 2013-05-16 14:30:00
abstract: 

Security vulnerabilities, or defects in programs that enable their security to be breached, frequently facilitate successful attacks against systems. While software quality metrics to predict defects have been proposed and evaluated in the past, less is known about the performance of security metrics in predicting vulnerabilities and the contexts in which they are effective. In the proposed research, we build a corpus of security vulnerabilities from open-source software, propose security metrics for software artifacts, and empirically evaluate them with respect to current quality and security metrics. 
We build a diverse, representative corpus of vulnerabilities in web applications, storing them in a structured format which links defect information with their relevant source code locations. This corpus will be used to measure the vulnerability prediction performance of traditional metric suites, using processes that avoid confounding variables to which other testing methods are prone. We will then propose, adapt, and evaluate metrics which quantify security-related characteristics such as attack surface, exposure, and privilege, utilizing an established theoretical evaluation method to study these metrics properties.
One product of this research is a substantial corpus of security vulnerabilities, which will become available to the research community to facilitate empirical studies of vulnerabilities and security hardening techniques. Another outcome of this research is unified, comparative data on the vulnerability prediction performance of traditional quality metrics and security-specific metrics, some of which are new or otherwise have not been evaluated. These results are enabled by the application of theoretical and empirical validation methods to attack surface metrics, which have not yet been examined in this way. Finally, this research will produce measurement tools for developers and testers, allowing security metrics to be leveraged for tasks such as estimating the relative security risks of programs or portions of programs, prioritizing code reviews or defense-in-depth measures for specific components, and assessing the security impact of adding a new component
Examining Committee:
Dr. James Purtilo -  Chair
Dr. James Reggia -  Deps Representative
Dr. Michael Hicks -  Committee Member
bio: 
locationRoomNumber: 4103
eventWebsite: https://talks.cs.umd.edu/talks/347
title: PhD Proposal: Developing and Validating Security Vulnerability Indicator Metrics
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777350
speaker: Mario Alvim
speakerAffiliation: UPenn
speakerUrl: http://hans.math.upenn.edu/~msalvim/
startDateTime: 2013-05-16 13:00:00
endDateTime: 2013-05-16 14:00:00
abstract: Joint work with Andre Scedrov and Fred B. Schneider

Abstract:
---------
Quantitative information flow (QIF) is concerned with measuring how much information about a system's secrets is being leaked to an adversary. The adversary is presumed to have a priori information about the secrets before execution starts and to access public obervables as execution proceeds. By combining a priori information and public observables, the adversary achieves a posteiori information about the secrets. The leakage from an execution is then computed either (i) as the difference between a posteriori information and a priori information or, equivalently, (ii) as the difference between a priori uncertainty and a posteriori uncertainty (since knowledge of information is the dual of uncertainty).

Approaches to QIF traditionally have presumed that all leaks involving a given number of bits are equally harmful. The presumption is unrealistic, so we describe a new approach to QIF. Here, secrets are defined in terms of fields, where derived secrets obtained by combining these fields can be assigned a different worth (perhaps in proportion to the harm that would result from disclosure). New measures that incorporate worth into QIF are then defined; they generalize probability of guessing, guessing entropy, and Shannon entropy. A lattice of information is derived to provide an underlying algebraic structure for an adversary's state of knowledge in this more-general setting.

Finally, we discuss directions to define worth assignments that are soundly based on the the relevant aspects of the scenario of interest. We take particular interest for defining worth assignments for anonymity systems.
bio: 
locationRoomNumber: 3450
eventWebsite: https://talks.cs.umd.edu/talks/350
title: When not all bits are equal: incorporating "worth" into information-flow measures
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
id: 777348
speaker: Pankaj Jalote
speakerAffiliation: IIIT-Delhi
speakerUrl: http://www.iiitd.edu.in/~jalote/
startDateTime: 2013-05-17 11:00:00
endDateTime: 2013-05-17 12:00:00
abstract: Challenges in Engineering Education in Indiaand Opportunities at IIIT-Delhi
Pankaj Jalote
Professor and Director
Indraprastha Institute of Information Technology (IIIT) Delhi
New Delhi
The challenges faced by countries like India in engineering education tend to be different from those in developed countries. This talk will discuss the challenge of growth and scale, quality and faculty, and the RD ecosystem. Within the RD ecosystem challenge, it will discuss the role of research and research universities, issue of PhD production, the importance of relevant industry, and appropriateness of research agenda.
The second part of the talk will discuss the background of IIIT-Delhi, its current state, and the exciting opportunity it offers to young researchers who want to make a mark in academics from India.
bio: 
locationRoomNumber: 2120
eventWebsite: https://talks.cs.umd.edu/talks/348
title: Challenges in Engineering Education in India and Opportunities at IIIT-Delhi
locationName: Computer Science Instructional Center
facilId: 406
buildingAbbreviation: CSI
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=CSI
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777349
speaker: Udayan Khurana
speakerAffiliation: 
speakerUrl: 
startDateTime: 2013-05-17 15:00:00
endDateTime: 2013-05-17 16:30:00
abstract: 

Over the last decade, we have witnessed an increasing availability of large volumes of temporally annotated data forinformation networks such as social networks, financial transaction networks, transportation networks and many others.This has fueled an interest in temporal or dynamic analysis, which has the potential to provide crucial insights intovarious temporal or evolutionary aspects of a network.We address the problem of managing historical data for such large evolving information networkswith the goal to enable temporal and evolutionary queries and analytics.
In the first part of this proposal, we present the design and architecture of a distributed graphdatabase system. It stores the entire history of a network and provides support forefficient retrieval of multiple graphs from arbitrary time points in the past, in addition tomaintaining the current state for ongoing updates.Our system exposes a general programmatic API to process and analyze the retrieved snapshots.We introduceDeltaGraph, anovel, extensible, highly tunable, and distributed hierarchical index structure that enables compact recording of thehistorical information. DeltaGraph supports efficient retrieval of historical graph snapshots for single-siteor parallel processing.Along with the original graph data, DeltaGraph can also maintain and indexauxiliaryinformation using itsextensibilityframework; this functionality can be used to extend the structure to efficiently execute queries likesubgraph patternmatchingover historical data.We develop analytical models for both the storage space needed and the snapshot retrieval times to aidin choosing the right parameters for a specific scenario. In addition, we present strategies for materializingportions of the historical graph state in memory to further speed up the retrieval process.We also present an in-memory graph data structure calledGraphPoolthat can maintain hundreds ofhistorical graph instances in main memory in a non-redundant manner. 
In the second part of the proposal, we focus on diversified needs of a historical graph data management system. First, we proposemodifications to DeltaGraph to enable efficient retrieval of subgraphs forego-centricandneighborhood-centricanalysis queries. Second, we proposestudying and dealing with runtime challenges of a dynamic historical graph database such as handling updates, optimizing multiple queries together andadapting to changing query-loads. Third, we focus our attention on efficiently executing specific queries such asevolving shortest pathsordynamic reachabilityusing DeltaGraph's extensibility framework. We also look at understanding and hence optimizing historical networkanalysis queries expressed in a declarative syntax. Finally, we explore the applicability of some of these techniques to large scale dynamic dataother than graphs, particularly, scientific array databases and timeseries data.
Examining Committee:
Dr. Amol Deshpande       - Chair
Dr. Ben Shneiderman      -  Deps Representative
Dr. Nick Roussopoulos     -  Committee Member
bio: 
locationRoomNumber: 4172
eventWebsite: https://talks.cs.umd.edu/talks/349
title: PhD Proposal: Historical Graph Data Management
locationName: A.V. Williams Building
facilId: 115
buildingAbbreviation: AVW
buildingUrl: http://www.umd.edu/CampusMaps/bld_detail.cfm?bld_code=AVW
categories: 7
timeStamp: 2013-05-07 08:57:18
Info: Event is already in the database
id: 777332
speaker: HCIL
speakerAffiliation: 
speakerUrl: http://www.cs.umd.edu/hcil/soh/index.shtml
startDateTime: 2013-05-22 08:30:00
endDateTime: 2013-05-22 17:00:00
abstract: HCIL's 30th Annual Symposium will highlight the cutting-edge research being conducted in the Human-Computer Interaction Lab at the University of Maryland. The Symposium will take place on Wednesday, May 22nd and Thursday, May 23rd and will feature parallel sessions of talks, tutorials and workshops on both days as well as posters, demos and videos of our work. For more information, please visit http://www.cs.umd.edu/hcil/soh/.
bio: 
locationRoomNumber: 
eventWebsite: https://talks.cs.u